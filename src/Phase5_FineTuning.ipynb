{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0eed87",
   "metadata": {},
   "source": [
    "# Model Selection for SLP Prediction\n",
    "\n",
    "This notebook performs model selection to predict the `slp` column using various machine learning algorithms with time series cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import clone\n",
    "from lightgbm import LGBMRegressor\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05222b9e",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b1834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1460, 27)\n",
      "\n",
      "Columns: ['date', 'slp', 'holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration', 'day_of_week_sin', 'day_of_week_cos', 'winddirection_10m_dominant_sin', 'winddirection_10m_dominant_cos', 'day_of_year_sin', 'day_of_year_cos']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>slp</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weathercode</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <th>apparent_temperature_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <th>windgusts_10m_max</th>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>winddirection_10m_dominant_sin</th>\n",
       "      <th>winddirection_10m_dominant_cos</th>\n",
       "      <th>day_of_year_sin</th>\n",
       "      <th>day_of_year_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>638555.753</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.389530</td>\n",
       "      <td>0.248483</td>\n",
       "      <td>0.271326</td>\n",
       "      <td>0.228208</td>\n",
       "      <td>0.105172</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068171</td>\n",
       "      <td>-0.101238</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.290285</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.241922</td>\n",
       "      <td>-0.970296</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.008583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>556131.836</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.520484</td>\n",
       "      <td>0.218630</td>\n",
       "      <td>0.472330</td>\n",
       "      <td>0.519480</td>\n",
       "      <td>0.251962</td>\n",
       "      <td>0.439128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282560</td>\n",
       "      <td>0.124197</td>\n",
       "      <td>-0.023733</td>\n",
       "      <td>0.055099</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>0.008583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>487753.707</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.972872</td>\n",
       "      <td>1.412763</td>\n",
       "      <td>1.115543</td>\n",
       "      <td>0.911192</td>\n",
       "      <td>1.022609</td>\n",
       "      <td>0.916267</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063735</td>\n",
       "      <td>0.769408</td>\n",
       "      <td>-0.652673</td>\n",
       "      <td>0.612119</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.173648</td>\n",
       "      <td>-0.984808</td>\n",
       "      <td>-0.999668</td>\n",
       "      <td>0.025748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>615408.403</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.382823</td>\n",
       "      <td>0.338327</td>\n",
       "      <td>0.368822</td>\n",
       "      <td>0.472147</td>\n",
       "      <td>0.450224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052229</td>\n",
       "      <td>-0.241164</td>\n",
       "      <td>-1.121221</td>\n",
       "      <td>-0.910402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.731354</td>\n",
       "      <td>-0.681998</td>\n",
       "      <td>-0.999079</td>\n",
       "      <td>0.042905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>757789.344</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.086669</td>\n",
       "      <td>0.532090</td>\n",
       "      <td>0.097122</td>\n",
       "      <td>0.127769</td>\n",
       "      <td>0.594472</td>\n",
       "      <td>0.217203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450788</td>\n",
       "      <td>-0.552109</td>\n",
       "      <td>-1.156583</td>\n",
       "      <td>-1.071319</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>-0.913545</td>\n",
       "      <td>-0.998195</td>\n",
       "      <td>0.060049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         slp  holiday  weathercode  temperature_2m_max  \\\n",
       "0  2021-10-01  638555.753        0            3            0.389530   \n",
       "1  2021-10-02  556131.836        0            3            0.520484   \n",
       "2  2021-10-03  487753.707        1           51            0.972872   \n",
       "3  2021-10-04  615408.403        0           51            0.318100   \n",
       "4  2021-10-05  757789.344        0           63           -0.086669   \n",
       "\n",
       "   temperature_2m_min  temperature_2m_mean  apparent_temperature_max  \\\n",
       "0            0.248483             0.271326                  0.228208   \n",
       "1            0.218630             0.472330                  0.519480   \n",
       "2            1.412763             1.115543                  0.911192   \n",
       "3            0.382823             0.338327                  0.368822   \n",
       "4            0.532090             0.097122                  0.127769   \n",
       "\n",
       "   apparent_temperature_min  apparent_temperature_mean  ...  \\\n",
       "0                  0.105172                   0.150625  ...   \n",
       "1                  0.251962                   0.439128  ...   \n",
       "2                  1.022609                   0.916267  ...   \n",
       "3                  0.472147                   0.450224  ...   \n",
       "4                  0.594472                   0.217203  ...   \n",
       "\n",
       "   windspeed_10m_max  windgusts_10m_max  shortwave_radiation_sum  \\\n",
       "0          -0.068171          -0.101238                 0.129082   \n",
       "1           0.282560           0.124197                -0.023733   \n",
       "2           1.063735           0.769408                -0.652673   \n",
       "3          -0.052229          -0.241164                -1.121221   \n",
       "4          -0.450788          -0.552109                -1.156583   \n",
       "\n",
       "   et0_fao_evapotranspiration  day_of_week_sin  day_of_week_cos  \\\n",
       "0                    0.290285        -0.433884        -0.900969   \n",
       "1                    0.055099        -0.974928        -0.222521   \n",
       "2                    0.612119        -0.781831         0.623490   \n",
       "3                   -0.910402         0.000000         1.000000   \n",
       "4                   -1.071319         0.781831         0.623490   \n",
       "\n",
       "   winddirection_10m_dominant_sin  winddirection_10m_dominant_cos  \\\n",
       "0                        0.241922                       -0.970296   \n",
       "1                       -0.104528                       -0.994522   \n",
       "2                        0.173648                       -0.984808   \n",
       "3                       -0.731354                       -0.681998   \n",
       "4                        0.406737                       -0.913545   \n",
       "\n",
       "   day_of_year_sin  day_of_year_cos  \n",
       "0        -0.999963        -0.008583  \n",
       "1        -0.999963         0.008583  \n",
       "2        -0.999668         0.025748  \n",
       "3        -0.999079         0.042905  \n",
       "4        -0.998195         0.060049  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset configurations\n",
    "data_names = ['full', 'stat', 'rf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063a7cc",
   "metadata": {},
   "source": [
    "## 3. Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c74604",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 10\n",
    "tscv = TimeSeriesSplit(n_splits = n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7720c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_params(estimator, X, y, tscv):\n",
    "    \"\"\"Valuta un singolo estimator (clonato) con TimeSeriesSplit.\n",
    "    Ritorna dizionario di metriche medie.\n",
    "    \"\"\"\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model = clone(estimator)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    return {\n",
    "        'RMSE_mean': np.mean(rmse_scores),\n",
    "        'RMSE_std': np.std(rmse_scores),\n",
    "        'MAE_mean': np.mean(mae_scores),\n",
    "        'MAE_std': np.std(mae_scores),\n",
    "        'R2_mean': np.mean(r2_scores),\n",
    "        'R2_std': np.std(r2_scores),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e6b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_iter(grid_dict):\n",
    "    \"\"\"Genera tutte le combinazioni dalla dict di liste come sklearn.model_selection.ParameterGrid.\n",
    "    grid_dict: {'param': [v1,v2,...], ...}\n",
    "    \"\"\"\n",
    "    keys = list(grid_dict.keys())\n",
    "    for values in itertools.product(*(grid_dict[k] for k in keys)):\n",
    "        yield dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a0b0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_results(results_list, k=5, metric='R2_mean'):\n",
    "    \"\"\"Ordina la lista di dict (ognuno con 'params' e metriche) e ritorna top k.\n",
    "    metric: campo su cui ordinare (default R2_mean decrescente).\n",
    "    \"\"\"\n",
    "    return sorted(results_list, key=lambda r: r.get(metric, -np.inf), reverse=True)[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f3197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fine_grid_around(best_params, param_specs, factor=0.5, n_points=5):\n",
    "    \"\"\"Crea una lista di param dict per la fine search intorno ai best_params.\n",
    "    param_specs for each param: {'type':'int'/'float'/'cat', 'bounds':(min,max)}\n",
    "    factor: estensione percentuale (es 0.5 = +/-50%)\n",
    "    n_points: quanti punti generare per ogni parametro\n",
    "    \"\"\"\n",
    "    fine_specs = {}\n",
    "    for p, spec in param_specs.items():\n",
    "        best = best_params.get(p, None)\n",
    "        if best is None:\n",
    "            # se non presente, usa bounds\n",
    "            lo, hi = spec.get('bounds', (None, None))\n",
    "            if spec['type'] == 'cat':\n",
    "                fine_specs[p] = spec['values']\n",
    "            elif spec['type'] == 'int':\n",
    "                fine_specs[p] = list(range(\n",
    "                    max(1, int(lo)),\n",
    "                    int(hi) + 1,\n",
    "                    max(1, int((int(hi)-int(lo))//(n_points-1) if n_points>1 else 1))\n",
    "                ))\n",
    "            else:\n",
    "                fine_specs[p] = list(np.linspace(lo, hi, n_points))\n",
    "            continue\n",
    "\n",
    "        if spec['type'] == 'cat':\n",
    "            fine_specs[p] = spec['values']\n",
    "\n",
    "        elif spec['type'] == 'int':\n",
    "            lo = max(spec['bounds'][0], int(best - max(1, factor * best)))\n",
    "            hi = min(spec['bounds'][1], int(best + max(1, factor * best)))\n",
    "            if lo >= hi:\n",
    "                fine_specs[p] = [int(best)]\n",
    "            else:\n",
    "                fine_specs[p] = sorted(list(set([int(x) for x in np.linspace(lo, hi, n_points)])))\n",
    "\n",
    "        else:  # float\n",
    "            lo = max(spec['bounds'][0], best * (1 - factor))\n",
    "            hi = min(spec['bounds'][1], best * (1 + factor))\n",
    "            fine_specs[p] = list(np.linspace(lo, hi, n_points))\n",
    "\n",
    "    combos = list(itertools.islice(param_grid_iter(fine_specs), 10000))\n",
    "    return combos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d00bd",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded42873",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_space = {\n",
    "    'RandomForest': {\n",
    "        'estimator': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        'coarse': {\n",
    "            'n_estimators': [50, 100, 300],\n",
    "            'max_depth': [5, 10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['sqrt', 'log2', 0.5]\n",
    "        },\n",
    "        'specs': {\n",
    "            'n_estimators': {'type':'int', 'bounds':(10,1000)},\n",
    "            'max_depth': {'type':'int', 'bounds':(3,50)},\n",
    "            'min_samples_split': {'type':'int', 'bounds':(2,50)},\n",
    "            'max_features': {'type':'cat', 'values':['sqrt','log2',0.2,0.3,0.4,0.5,None]}\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'estimator': GradientBoostingRegressor(random_state=42),\n",
    "        'coarse': {\n",
    "            'n_estimators': [100, 300, 800],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 8],\n",
    "            'subsample': [0.6, 0.8, 1.0]\n",
    "        },\n",
    "        'specs': {\n",
    "            'n_estimators': {'type':'int', 'bounds':(50,2000)},\n",
    "            'learning_rate': {'type':'float', 'bounds':(1e-4,1.0)},\n",
    "            'max_depth': {'type':'int', 'bounds':(1,20)},\n",
    "            'subsample': {'type':'float', 'bounds':(0.3,1.0)}\n",
    "        }\n",
    "    },\n",
    "    # 'LightGBM': {\n",
    "    #     'estimator': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    #     'coarse': {\n",
    "    #         'n_estimators': [100, 300, 1000],\n",
    "    #         'learning_rate': [0.01, 0.05, 0.1],\n",
    "    #         'num_leaves': [15, 31, 63],\n",
    "    #         'max_depth': [-1, 5, 10]\n",
    "    #     },\n",
    "    #     'specs': {\n",
    "    #         'n_estimators': {'type':'int', 'bounds':(50,3000)},\n",
    "    #         'learning_rate': {'type':'float', 'bounds':(1e-4,1.0)},\n",
    "    #         'num_leaves': {'type':'int', 'bounds':(6,2048)},\n",
    "    #         'max_depth': {'type':'int', 'bounds':(-1,50)},\n",
    "    #         'min_child_samples': {'type':'int', 'bounds':(1,100)}\n",
    "    #     }\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8ff1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_param_set(estimator, params, X, y, tscv):\n",
    "    est = clone(estimator).set_params(**params)\n",
    "    metrics = evaluate_model_params(est, X, y, tscv)\n",
    "    return {'params': params, **metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417a560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_to_fine_search(name, model_info, X, y, tscv, top_k=5):\n",
    "    print('\\n' + '='*60)\n",
    "    print(f'Inizio ricerca per: {name}')\n",
    "    estimator = model_info['estimator']\n",
    "    coarse_grid = model_info['coarse']\n",
    "    specs = model_info['specs']\n",
    "\n",
    "    # ------- COARSE SEARCH PARALLEL -------\n",
    "    param_list = list(param_grid_iter(coarse_grid))\n",
    "    print(f'Coarse grid size: {len(param_list)} combinazioni')\n",
    "\n",
    "    coarse_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(evaluate_param_set)(estimator, params, X, y, tscv)\n",
    "        for params in param_list\n",
    "    )\n",
    "\n",
    "    # top-k\n",
    "    top_coarse = top_k_results(coarse_results, k=top_k, metric='R2_mean')\n",
    "    print('\\nTop risultati (coarse):')\n",
    "    for r in top_coarse:\n",
    "        print(f\"  R2={r['R2_mean']:.4f} — params={r['params']}\")\n",
    "\n",
    "    # ------- FINE SEARCH PARALLEL -------\n",
    "    best_coarse = top_coarse[0]\n",
    "    best_params = best_coarse['params']\n",
    "\n",
    "    fine_param_list = make_fine_grid_around(best_params, specs, factor=0.5, n_points=7)\n",
    "    print(f\"\\nFine grid size (limitata): {len(fine_param_list)} combinazioni\\n\")\n",
    "\n",
    "    fine_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(evaluate_param_set)(estimator, params, X, y, tscv)\n",
    "        for params in fine_param_list\n",
    "    )\n",
    "\n",
    "    top_fine = top_k_results(fine_results, k=3, metric='R2_mean')\n",
    "    print('\\nTop risultati (fine):')\n",
    "    for r in top_fine:\n",
    "        print(f\"  R2={r['R2_mean']:.4f} — params={r['params']}\")\n",
    "\n",
    "    best_final = top_fine[0]\n",
    "    return {\n",
    "        'coarse_results': coarse_results,\n",
    "        'top_coarse': top_coarse,\n",
    "        'fine_results': fine_results,\n",
    "        'top_fine': top_fine,\n",
    "        'best': best_final\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9da566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(estimator, X_test, y_test):\n",
    "    \"\"\"Valuta un modello già fit su un test set con metriche aggiuntive.\"\"\"\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    bias = np.mean(y_pred - y_test)\n",
    "    max_error = np.max(np.abs(y_pred - y_test))\n",
    "    pearson_corr = pearsonr(y_test, y_pred)[0]\n",
    "    spearman_corr = spearmanr(y_test, y_pred)[0]\n",
    "    mape = np.mean(np.abs((y_test - y_pred)/y_test)) * 100  # attenzione valori vicino a zero\n",
    "    smape = np.mean(np.abs(y_test - y_pred)/((np.abs(y_test)+np.abs(y_pred))/2)) * 100\n",
    "    \n",
    "    return {\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'Bias': bias,\n",
    "        'Max_Error': max_error,\n",
    "        'Pearson': pearson_corr,\n",
    "        'Spearman': spearman_corr,\n",
    "        'MAPE': mape,\n",
    "        'sMAPE': smape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_pipeline(data_name):    \n",
    "    out_path = f'results/{data_name}'\n",
    "    dataset = f'dataset/data_v3_{data_name}.csv'\n",
    "    df = pd.read_csv(dataset, sep=';', decimal=',')\n",
    "\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Parse date and sort by date (important for time series)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['date', 'slp'])\n",
    "    y = df['slp']\n",
    "\n",
    "    test_days = 365\n",
    "    X_test = X.iloc[-test_days:]\n",
    "    y_test = y.iloc[-test_days:]\n",
    "\n",
    "    X_train = X.iloc[:-test_days]\n",
    "    y_train = y.iloc[:-test_days]  \n",
    "    \n",
    "    all_best = {}\n",
    "    for name, info in models_space.items():\n",
    "        res = coarse_to_fine_search(name, info, X_train, y_train, tscv, top_k=3)\n",
    "        best_entry = res['best']\n",
    "        all_best[name] = best_entry\n",
    "        # salva i risultati intermedi su disco per controllo laterale\n",
    "        joblib.dump(res, f'{out_path}/results_{name}_coarse_to_fine_{data_name}.pkl')\n",
    "        print(f\"Risultati salvati in {out_path}/results_{name}_coarse_to_fine_{data_name}.pkl\")\n",
    "        \n",
    "    summary = []\n",
    "    for name, best in all_best.items():\n",
    "        summary.append({\n",
    "            'model': name,\n",
    "            'R2_mean': best['R2_mean'],\n",
    "            'RMSE_mean': best['RMSE_mean'],\n",
    "            'MAE_mean': best['MAE_mean'],\n",
    "            'best_params': best['params']\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary).sort_values('R2_mean', ascending=False).reset_index(drop=True)\n",
    "    print('\\n' + '='*80)\n",
    "    print('CONFRONTO FINALE: modelli ottimizzati')\n",
    "    print(summary_df)\n",
    "    \n",
    "    print('\\nFit e salvataggio dei modelli finali (su tutto il dataset):')\n",
    "    for idx, row in summary_df.iterrows():\n",
    "        name = row['model']\n",
    "        best_params = row['best_params']\n",
    "        estimator = models_space[name]['estimator'].set_params(**best_params)\n",
    "        print(f\"  Fit model: {name} con params: {best_params}\")\n",
    "        estimator.fit(X_train, y_train)\n",
    "        joblib.dump(estimator, f'{out_path}/best_model_{name}_{data_name}.pkl')\n",
    "        print(f\"  Salvato: {out_path}/best_model_{name}_{data_name}.pkl\")\n",
    "\n",
    "    print('\\nDONE')\n",
    "    \n",
    "    test_results = []\n",
    "\n",
    "    for _, row in summary_df.iterrows():\n",
    "        name = row['model']\n",
    "        model_file = f'{out_path}/best_model_{name}_{data_name}.pkl'\n",
    "        \n",
    "        # Carica modello già fit\n",
    "        model = joblib.load(model_file)\n",
    "        \n",
    "        # Valutazione sul test set\n",
    "        metrics = evaluate_on_test(model, X_test, y_test)\n",
    "        \n",
    "        metrics['model'] = name\n",
    "        metrics['best_params'] = row['best_params']\n",
    "        test_results.append(metrics)\n",
    "\n",
    "    # Trasforma in DataFrame\n",
    "    test_results_df = pd.DataFrame(test_results).sort_values('R2', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Stampa\n",
    "    print('\\n=== Risultati sui test set ===')\n",
    "    print(test_results_df)\n",
    "    \n",
    "    # Salva in CSV\n",
    "    test_results_df.to_csv(f'{out_path}/test_set_results_{data_name}.csv', index=False)\n",
    "\n",
    "    # Salva anche in pickle per uso successivo\n",
    "    joblib.dump(test_results_df, f'{out_path}/test_set_results_{data_name}.pkl')\n",
    "\n",
    "    print(f\"\\nRisultati test set salvati in '{out_path}/test_set_results_{data_name}.csv' e '{out_path}/test_set_results_{data_name}.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bfa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_name in data_names:\n",
    "    fine_tune_pipeline(data_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
