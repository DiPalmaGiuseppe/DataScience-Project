{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0eed87",
   "metadata": {},
   "source": [
    "# Model Selection for SLP Prediction\n",
    "\n",
    "This notebook performs model selection to predict the `slp` column using various machine learning algorithms with time series cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import clone\n",
    "from lightgbm import LGBMRegressor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import time\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05222b9e",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253b1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configurations\n",
    "data_names = ['full', 'stat', 'rf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063a7cc",
   "metadata": {},
   "source": [
    "## 3. Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c74604",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 10\n",
    "tscv = TimeSeriesSplit(n_splits = n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7720c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_params(estimator, X, y, tscv):\n",
    "    \"\"\"Valuta un singolo estimator (clonato) con TimeSeriesSplit.\n",
    "    Ritorna dizionario di metriche medie.\n",
    "    \"\"\"\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model = clone(estimator)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    return {\n",
    "        'RMSE_mean': np.mean(rmse_scores),\n",
    "        'RMSE_std': np.std(rmse_scores),\n",
    "        'MAE_mean': np.mean(mae_scores),\n",
    "        'MAE_std': np.std(mae_scores),\n",
    "        'R2_mean': np.mean(r2_scores),\n",
    "        'R2_std': np.std(r2_scores),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e6b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_iter(grid_dict):\n",
    "    \"\"\"Genera tutte le combinazioni dalla dict di liste come sklearn.model_selection.ParameterGrid.\n",
    "    grid_dict: {'param': [v1,v2,...], ...}\n",
    "    \"\"\"\n",
    "    keys = list(grid_dict.keys())\n",
    "    for values in itertools.product(*(grid_dict[k] for k in keys)):\n",
    "        yield dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_results(results_list, k=5, metric='R2_mean'):\n",
    "    \"\"\"Ordina la lista di dict (ognuno con 'params' e metriche) e ritorna top k.\n",
    "    metric: campo su cui ordinare (default R2_mean decrescente).\n",
    "    \"\"\"\n",
    "    return sorted(results_list, key=lambda r: r.get(metric, -np.inf), reverse=True)[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f3197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fine_grid_around(best_params, param_specs, factor=0.5, n_points=5):\n",
    "    \"\"\"Crea una lista di param dict per la fine search intorno ai best_params.\n",
    "    param_specs for each param: {'type':'int'/'float'/'cat', 'bounds':(min,max)}\n",
    "    factor: estensione percentuale (es 0.5 = +/-50%)\n",
    "    n_points: quanti punti generare per ogni parametro\n",
    "    \"\"\"\n",
    "    fine_specs = {}\n",
    "    for p, spec in param_specs.items():\n",
    "        best = best_params.get(p, None)\n",
    "        if best is None:\n",
    "            # se non presente, usa bounds\n",
    "            lo, hi = spec.get('bounds', (None, None))\n",
    "            if spec['type'] == 'cat':\n",
    "                fine_specs[p] = spec['values']\n",
    "            elif spec['type'] == 'int':\n",
    "                fine_specs[p] = list(range(\n",
    "                    max(1, int(lo)),\n",
    "                    int(hi) + 1,\n",
    "                    max(1, int((int(hi)-int(lo))//(n_points-1) if n_points>1 else 1))\n",
    "                ))\n",
    "            else:\n",
    "                fine_specs[p] = list(np.linspace(lo, hi, n_points))\n",
    "            continue\n",
    "\n",
    "        if spec['type'] == 'cat':\n",
    "            fine_specs[p] = spec['values']\n",
    "\n",
    "        elif spec['type'] == 'int':\n",
    "            lo = max(spec['bounds'][0], int(best - max(1, factor * best)))\n",
    "            hi = min(spec['bounds'][1], int(best + max(1, factor * best)))\n",
    "            if lo >= hi:\n",
    "                fine_specs[p] = [int(best)]\n",
    "            else:\n",
    "                fine_specs[p] = sorted(list(set([int(x) for x in np.linspace(lo, hi, n_points)])))\n",
    "\n",
    "        else:  # float\n",
    "            lo = max(spec['bounds'][0], best * (1 - factor))\n",
    "            hi = min(spec['bounds'][1], best * (1 + factor))\n",
    "            fine_specs[p] = list(np.linspace(lo, hi, n_points))\n",
    "\n",
    "    combos = list(itertools.islice(param_grid_iter(fine_specs), 10000))\n",
    "    return combos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d00bd",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded42873",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_space = {\n",
    "    'RandomForest': {\n",
    "        'estimator': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        'coarse': {\n",
    "            'n_estimators': [50, 100, 300],\n",
    "            'max_depth': [5, 10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['sqrt', 'log2', 0.5]\n",
    "        },\n",
    "        'specs': {\n",
    "            'n_estimators': {'type':'int', 'bounds':(10,1000)},\n",
    "            'max_depth': {'type':'int', 'bounds':(3,50)},\n",
    "            'min_samples_split': {'type':'int', 'bounds':(2,50)},\n",
    "            'max_features': {'type':'cat', 'values':['sqrt','log2',0.2,0.3,0.4,0.5,None]}\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'estimator': GradientBoostingRegressor(random_state=42),\n",
    "        'coarse': {\n",
    "            'n_estimators': [100, 300, 800],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 8],\n",
    "            'subsample': [0.6, 0.8, 1.0]\n",
    "        },\n",
    "        'specs': {\n",
    "            'n_estimators': {'type':'int', 'bounds':(50,1500)},\n",
    "            'learning_rate': {'type':'float', 'bounds':(1e-4,1.0)},\n",
    "            'max_depth': {'type':'int', 'bounds':(1,20)},\n",
    "            'subsample': {'type':'float', 'bounds':(0.3,1.0)}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8ff1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_param_set(estimator, params, X, y, tscv):\n",
    "    est = clone(estimator).set_params(**params)\n",
    "    metrics = evaluate_model_params(est, X, y, tscv)\n",
    "    return {'params': params, **metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417a560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_to_fine_search(name, model_info, X, y, tscv, top_k=5):\n",
    "    print('\\n' + '='*60)\n",
    "    print(f'Inizio ricerca per: {name}')\n",
    "    estimator = model_info['estimator']\n",
    "    coarse_grid = model_info['coarse']\n",
    "    specs = model_info['specs']\n",
    "\n",
    "    # ------- COARSE SEARCH PARALLEL -------\n",
    "    param_list = list(param_grid_iter(coarse_grid))\n",
    "    print(f'Coarse grid size: {len(param_list)} combinazioni')\n",
    "\n",
    "    start_time = time.time()\n",
    "    coarse_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(evaluate_param_set)(estimator, params, X, y, tscv)\n",
    "        for params in param_list\n",
    "    )\n",
    "\n",
    "    # top-k\n",
    "    top_coarse = top_k_results(coarse_results, k=top_k, metric='R2_mean')\n",
    "    print('\\nTop risultati (coarse):')\n",
    "    for r in top_coarse:\n",
    "        print(f\"  R2={r['R2_mean']:.4f} — params={r['params']}\")\n",
    "\n",
    "    # ------- FINE SEARCH PARALLEL -------\n",
    "    best_coarse = top_coarse[0]\n",
    "    best_params = best_coarse['params']\n",
    "\n",
    "    fine_param_list = make_fine_grid_around(best_params, specs, factor=0.5, n_points=7)\n",
    "    print(f\"\\nFine grid size (limitata): {len(fine_param_list)} combinazioni\\n\")\n",
    "\n",
    "    fine_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(evaluate_param_set)(estimator, params, X, y, tscv)\n",
    "        for params in fine_param_list\n",
    "    )\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    top_fine = top_k_results(fine_results, k=3, metric='R2_mean')\n",
    "    print('\\nTop risultati (fine):')\n",
    "    for r in top_fine:\n",
    "        print(f\"  R2={r['R2_mean']:.4f} — params={r['params']}\")\n",
    "\n",
    "    best_final = top_fine[0]\n",
    "    best_final[\"search_time\"] = time_elapsed\n",
    "    return {\n",
    "        'search_time': time_elapsed,\n",
    "        'coarse_results': coarse_results,\n",
    "        'top_coarse': top_coarse,\n",
    "        'fine_results': fine_results,\n",
    "        'top_fine': top_fine,\n",
    "        'best': best_final,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d9da566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(estimator, X_test, y_test):\n",
    "    \"\"\"Valuta un modello già fit su un test set con metriche aggiuntive.\"\"\"\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    bias = np.mean(y_pred - y_test)\n",
    "    max_error = np.max(np.abs(y_pred - y_test))\n",
    "    pearson_corr = pearsonr(y_test, y_pred)[0]\n",
    "    spearman_corr = spearmanr(y_test, y_pred)[0]\n",
    "    mape = np.mean(np.abs((y_test - y_pred)/y_test)) * 100  # attenzione valori vicino a zero\n",
    "    smape = np.mean(np.abs(y_test - y_pred)/((np.abs(y_test)+np.abs(y_pred))/2)) * 100\n",
    "    \n",
    "    return {\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'Bias': bias,\n",
    "        'Max_Error': max_error,\n",
    "        'Pearson': pearson_corr,\n",
    "        'Spearman': spearman_corr,\n",
    "        'MAPE': mape,\n",
    "        'sMAPE': smape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0edf2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_pipeline(data_name):    \n",
    "    out_path = f'results/{data_name}'\n",
    "    dataset = f'dataset/data_v3_{data_name}.csv'\n",
    "    df = pd.read_csv(dataset, sep=';', decimal=',')\n",
    "\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Parse date and sort by date (important for time series)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['date', 'slp'])\n",
    "    y = df['slp']\n",
    "\n",
    "    test_days = 365\n",
    "    X_test = X.iloc[-test_days:]\n",
    "    y_test = y.iloc[-test_days:]\n",
    "\n",
    "    X_train = X.iloc[:-test_days]\n",
    "    y_train = y.iloc[:-test_days]  \n",
    "    \n",
    "    all_best = {}\n",
    "    for name, info in models_space.items():\n",
    "        res = coarse_to_fine_search(name, info, X_train, y_train, tscv, top_k=3)\n",
    "        best_entry = res['best']\n",
    "        all_best[name] = best_entry\n",
    "        # salva i risultati intermedi su disco per controllo laterale\n",
    "        joblib.dump(res, f'{out_path}/results_{name}_coarse_to_fine_{data_name}.pkl')\n",
    "        print(f\"Risultati salvati in {out_path}/results_{name}_coarse_to_fine_{data_name}.pkl\")\n",
    "        \n",
    "    summary = []\n",
    "    for name, best in all_best.items():\n",
    "        summary.append({\n",
    "            'model': name,\n",
    "            'search_time': best['search_time'],\n",
    "            'R2_mean': best['R2_mean'],\n",
    "            'RMSE_mean': best['RMSE_mean'],\n",
    "            'MAE_mean': best['MAE_mean'],\n",
    "            'best_params': best['params']\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary).sort_values('R2_mean', ascending=False).reset_index(drop=True)\n",
    "    print('\\n' + '='*80)\n",
    "    print('CONFRONTO FINALE: modelli ottimizzati')\n",
    "    print(summary_df)\n",
    "    \n",
    "    print('\\nFit e salvataggio dei modelli finali (su tutto il dataset):')\n",
    "    for idx, row in summary_df.iterrows():\n",
    "        name = row['model']\n",
    "        best_params = row['best_params']\n",
    "        estimator = models_space[name]['estimator'].set_params(**best_params)\n",
    "        print(f\"  Fit model: {name} con params: {best_params}\")\n",
    "        start_time = time.time()\n",
    "        estimator.fit(X_train, y_train)\n",
    "        fit_time = time.time() - start_time\n",
    "        summary_df.at[idx, 'fit_time'] = fit_time\n",
    "        joblib.dump(estimator, f'{out_path}/best_model_{name}_{data_name}.pkl')\n",
    "        print(f\"  Salvato: {out_path}/best_model_{name}_{data_name}.pkl\")\n",
    "\n",
    "    print('\\nDONE')\n",
    "    \n",
    "    test_results = []\n",
    "\n",
    "    for _, row in summary_df.iterrows():\n",
    "        name = row['model']\n",
    "        model_file = f'{out_path}/best_model_{name}_{data_name}.pkl'\n",
    "        \n",
    "        # Carica modello già fit\n",
    "        model = joblib.load(model_file)\n",
    "        \n",
    "        # Valutazione sul test set\n",
    "        metrics = evaluate_on_test(model, X_test, y_test)\n",
    "        \n",
    "        metrics['model'] = name\n",
    "        metrics['best_params'] = row['best_params']\n",
    "        metrics['search_time'] = row['search_time']\n",
    "        metrics['fit_time'] = row['fit_time']\n",
    "        test_results.append(metrics)\n",
    "        \n",
    "    print(test_results)        \n",
    "\n",
    "    # Trasforma in DataFrame\n",
    "    test_results_df = pd.DataFrame(test_results).sort_values('R2', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Stampa\n",
    "    print('\\n=== Risultati sui test set ===')\n",
    "    print(test_results_df)\n",
    "    \n",
    "    # Salva in CSV\n",
    "    test_results_df.to_csv(f'{out_path}/test_set_results_{data_name}.csv', index=False)\n",
    "\n",
    "    # Salva anche in pickle per uso successivo\n",
    "    joblib.dump(test_results_df, f'{out_path}/test_set_results_{data_name}.pkl')\n",
    "\n",
    "    print(f\"\\nRisultati test set salvati in '{out_path}/test_set_results_{data_name}.csv' e '{out_path}/test_set_results_{data_name}.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7bfa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1460, 27)\n",
      "\n",
      "Columns: ['date', 'slp', 'holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration', 'day_of_week_sin', 'day_of_week_cos', 'winddirection_10m_dominant_sin', 'winddirection_10m_dominant_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
      "\n",
      "============================================================\n",
      "Inizio ricerca per: RandomForest\n",
      "Coarse grid size: 108 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of 108 | elapsed:    6.0s remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of 108 | elapsed:    6.3s remaining:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of 108 | elapsed:    6.6s remaining:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 108 | elapsed:    8.0s remaining:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 108 | elapsed:    8.3s remaining:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 108 | elapsed:    8.5s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 108 | elapsed:    8.8s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 108 | elapsed:   12.5s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 108 | elapsed:   12.5s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 108 | elapsed:   12.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-0.3963 — params={'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "  R2=-0.3964 — params={'n_estimators': 50, 'max_depth': None, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "  R2=-0.4727 — params={'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "\n",
      "Fine grid size (limitata): 686 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 532 out of 686 | elapsed:   24.0s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 601 out of 686 | elapsed:   28.6s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 670 out of 686 | elapsed:   31.0s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 686 out of 686 | elapsed:   31.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-0.1997 — params={'n_estimators': 25, 'max_depth': 26, 'min_samples_split': 3, 'max_features': 'sqrt'}\n",
      "  R2=-0.1997 — params={'n_estimators': 25, 'max_depth': 26, 'min_samples_split': 3, 'max_features': 0.2}\n",
      "  R2=-0.1997 — params={'n_estimators': 25, 'max_depth': 23, 'min_samples_split': 3, 'max_features': 0.2}\n",
      "Risultati salvati in results/full/results_RandomForest_coarse_to_fine_full.pkl\n",
      "\n",
      "============================================================\n",
      "Inizio ricerca per: GradientBoosting\n",
      "Coarse grid size: 81 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of  81 | elapsed:    3.7s remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  81 | elapsed:    5.0s remaining:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  81 | elapsed:    7.3s remaining:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  81 | elapsed:    9.3s remaining:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  81 | elapsed:   12.9s remaining:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  81 | elapsed:   18.0s remaining:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  81 | elapsed:   23.1s remaining:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  81 | elapsed:   29.4s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  81 | elapsed:   40.0s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   58.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-0.4365 — params={'n_estimators': 800, 'learning_rate': 0.05, 'max_depth': 3, 'subsample': 1.0}\n",
      "  R2=-0.4468 — params={'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 3, 'subsample': 1.0}\n",
      "  R2=-0.4867 — params={'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1.0}\n",
      "\n",
      "Fine grid size (limitata): 1372 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 617 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 701 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 789 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 881 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 928 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 977 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1077 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1287 out of 1372 | elapsed:  6.2min remaining:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1372 out of 1372 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-0.2551 — params={'n_estimators': 533, 'learning_rate': np.float64(0.07500000000000001), 'max_depth': 2, 'subsample': np.float64(1.0)}\n",
      "  R2=-0.2609 — params={'n_estimators': 400, 'learning_rate': np.float64(0.07500000000000001), 'max_depth': 2, 'subsample': np.float64(1.0)}\n",
      "  R2=-0.2644 — params={'n_estimators': 666, 'learning_rate': np.float64(0.07500000000000001), 'max_depth': 2, 'subsample': np.float64(1.0)}\n",
      "Risultati salvati in results/full/results_GradientBoosting_coarse_to_fine_full.pkl\n",
      "\n",
      "================================================================================\n",
      "CONFRONTO FINALE: modelli ottimizzati\n",
      "              model  search_time   R2_mean      RMSE_mean       MAE_mean  \\\n",
      "0      RandomForest    44.519522 -0.199708  198013.771787  163214.386378   \n",
      "1  GradientBoosting   471.148737 -0.255093  198960.502801  162985.383495   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 25, 'max_depth': 26, 'min_sam...  \n",
      "1  {'n_estimators': 533, 'learning_rate': 0.07500...  \n",
      "\n",
      "Fit e salvataggio dei modelli finali (su tutto il dataset):\n",
      "  Fit model: RandomForest con params: {'n_estimators': 25, 'max_depth': 26, 'min_samples_split': 3, 'max_features': 'sqrt'}\n",
      "  Salvato: results/full/best_model_RandomForest_full.pkl\n",
      "  Fit model: GradientBoosting con params: {'n_estimators': 533, 'learning_rate': np.float64(0.07500000000000001), 'max_depth': 2, 'subsample': np.float64(1.0)}\n",
      "  Salvato: results/full/best_model_GradientBoosting_full.pkl\n",
      "\n",
      "DONE\n",
      "[{'R2': 0.9763532098768761, 'RMSE': np.float64(105830.57763595437), 'MAE': 72309.66805395643, 'Bias': np.float64(3465.911295567644), 'Max_Error': np.float64(540722.1010633332), 'Pearson': np.float64(0.9881926828983784), 'Spearman': np.float64(0.9878713695915583), 'MAPE': np.float64(8.74530340317958), 'sMAPE': np.float64(8.56110389396354), 'model': 'RandomForest', 'best_params': {'n_estimators': 25, 'max_depth': 26, 'min_samples_split': 3, 'max_features': 'sqrt'}, 'search_time': 44.519522190093994, 'fit_time': 0.11802268028259277}, {'R2': 0.9771104728268998, 'RMSE': np.float64(104122.23433243923), 'MAE': 71225.29288255534, 'Bias': np.float64(3804.382210142077), 'Max_Error': np.float64(534701.875686982), 'Pearson': np.float64(0.9889299705678741), 'Spearman': np.float64(0.9850008513830658), 'MAPE': np.float64(9.063128262864046), 'sMAPE': np.float64(9.14532769451509), 'model': 'GradientBoosting', 'best_params': {'n_estimators': 533, 'learning_rate': np.float64(0.07500000000000001), 'max_depth': 2, 'subsample': np.float64(1.0)}, 'search_time': 471.1487367153168, 'fit_time': 1.6410064697265625}]\n",
      "\n",
      "=== Risultati sui test set ===\n",
      "         R2           RMSE           MAE         Bias      Max_Error  \\\n",
      "0  0.977110  104122.234332  71225.292883  3804.382210  534701.875687   \n",
      "1  0.976353  105830.577636  72309.668054  3465.911296  540722.101063   \n",
      "\n",
      "    Pearson  Spearman      MAPE     sMAPE             model  \\\n",
      "0  0.988930  0.985001  9.063128  9.145328  GradientBoosting   \n",
      "1  0.988193  0.987871  8.745303  8.561104      RandomForest   \n",
      "\n",
      "                                         best_params  search_time  fit_time  \n",
      "0  {'n_estimators': 533, 'learning_rate': 0.07500...   471.148737  1.641006  \n",
      "1  {'n_estimators': 25, 'max_depth': 26, 'min_sam...    44.519522  0.118023  \n",
      "\n",
      "Risultati test set salvati in 'results/full/test_set_results_full.csv' e 'results/full/test_set_results_full.pkl'\n",
      "Dataset shape: (1095, 13)\n",
      "\n",
      "Columns: ['date', 'slp', 'temperature_2m_mean', 'sunrise', 'et0_fao_evapotranspiration', 'sunshine_duration', 'snowfall_sum', 'day_of_year', 'precipitation_hours', 'weathercode', 'windspeed_10m_max', 'rain_sum', 'holiday']\n",
      "\n",
      "============================================================\n",
      "Inizio ricerca per: RandomForest\n",
      "Coarse grid size: 108 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of 108 | elapsed:    3.1s remaining:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of 108 | elapsed:    3.2s remaining:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of 108 | elapsed:    3.4s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 108 | elapsed:    4.8s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 108 | elapsed:    5.1s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 108 | elapsed:    5.3s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 108 | elapsed:    5.4s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 108 | elapsed:    8.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 108 | elapsed:    8.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 108 | elapsed:    9.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-6.1646 — params={'n_estimators': 50, 'max_depth': None, 'min_samples_split': 2, 'max_features': 0.5}\n",
      "  R2=-6.1664 — params={'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 2, 'max_features': 0.5}\n",
      "  R2=-6.2884 — params={'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2, 'max_features': 0.5}\n",
      "\n",
      "Fine grid size (limitata): 686 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 532 out of 686 | elapsed:   17.2s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 601 out of 686 | elapsed:   19.6s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 670 out of 686 | elapsed:   21.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 686 out of 686 | elapsed:   22.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-5.9840 — params={'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 3, 'max_features': None}\n",
      "  R2=-6.0379 — params={'n_estimators': 58, 'max_depth': 10, 'min_samples_split': 2, 'max_features': None}\n",
      "  R2=-6.0868 — params={'n_estimators': 41, 'max_depth': 10, 'min_samples_split': 2, 'max_features': None}\n",
      "Risultati salvati in results/stat/results_RandomForest_coarse_to_fine_stat.pkl\n",
      "\n",
      "============================================================\n",
      "Inizio ricerca per: GradientBoosting\n",
      "Coarse grid size: 81 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of  81 | elapsed:    1.3s remaining:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  81 | elapsed:    1.9s remaining:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  81 | elapsed:    2.6s remaining:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  81 | elapsed:    4.5s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  81 | elapsed:    5.7s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  81 | elapsed:    7.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  81 | elapsed:   10.7s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  81 | elapsed:   12.6s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  81 | elapsed:   15.8s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   20.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-4.0370 — params={'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0}\n",
      "  R2=-4.0370 — params={'n_estimators': 800, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0}\n",
      "  R2=-4.0381 — params={'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0}\n",
      "\n",
      "Fine grid size (limitata): 2401 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 617 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 701 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 789 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 881 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 928 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 977 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1077 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1181 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1289 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1401 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1458 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1517 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1637 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1698 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1761 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1824 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1889 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2021 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2088 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2157 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2401 out of 2401 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-3.7851 — params={'n_estimators': 200, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 12, 'subsample': np.float64(0.75)}\n",
      "  R2=-3.7851 — params={'n_estimators': 250, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 12, 'subsample': np.float64(0.75)}\n",
      "  R2=-3.7851 — params={'n_estimators': 300, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 12, 'subsample': np.float64(0.75)}\n",
      "Risultati salvati in results/stat/results_GradientBoosting_coarse_to_fine_stat.pkl\n",
      "\n",
      "================================================================================\n",
      "CONFRONTO FINALE: modelli ottimizzati\n",
      "              model  search_time   R2_mean      RMSE_mean       MAE_mean  \\\n",
      "0  GradientBoosting   253.428339 -3.785145  202705.221992  165805.204160   \n",
      "1      RandomForest    31.614191 -5.983962  208499.839007  171739.081523   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 200, 'learning_rate': 0.15000...  \n",
      "1  {'n_estimators': 75, 'max_depth': 10, 'min_sam...  \n",
      "\n",
      "Fit e salvataggio dei modelli finali (su tutto il dataset):\n",
      "  Fit model: GradientBoosting con params: {'n_estimators': 200, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 12, 'subsample': np.float64(0.75)}\n",
      "  Salvato: results/stat/best_model_GradientBoosting_stat.pkl\n",
      "  Fit model: RandomForest con params: {'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 3, 'max_features': None}\n",
      "  Salvato: results/stat/best_model_RandomForest_stat.pkl\n",
      "\n",
      "DONE\n",
      "[{'R2': 0.9730694259317487, 'RMSE': np.float64(112940.02349688722), 'MAE': 75923.26656850538, 'Bias': np.float64(-20202.504836774682), 'Max_Error': np.float64(457750.12896451144), 'Pearson': np.float64(0.9868823091179613), 'Spearman': np.float64(0.986226102664459), 'MAPE': np.float64(8.872724878039286), 'sMAPE': np.float64(9.01817779263087), 'model': 'GradientBoosting', 'best_params': {'n_estimators': 200, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 12, 'subsample': np.float64(0.75)}, 'search_time': 253.42833924293518, 'fit_time': 0.7727386951446533}, {'R2': 0.977854859634072, 'RMSE': np.float64(102415.16920392576), 'MAE': 67686.74454470852, 'Bias': np.float64(-20018.500660977), 'Max_Error': np.float64(494618.51267971727), 'Pearson': np.float64(0.9893416865076842), 'Spearman': np.float64(0.9887032572188648), 'MAPE': np.float64(8.13178909805266), 'sMAPE': np.float64(8.186339366542308), 'model': 'RandomForest', 'best_params': {'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 3, 'max_features': None}, 'search_time': 31.614190578460693, 'fit_time': 0.22005629539489746}]\n",
      "\n",
      "=== Risultati sui test set ===\n",
      "         R2           RMSE           MAE          Bias      Max_Error  \\\n",
      "0  0.977855  102415.169204  67686.744545 -20018.500661  494618.512680   \n",
      "1  0.973069  112940.023497  75923.266569 -20202.504837  457750.128965   \n",
      "\n",
      "    Pearson  Spearman      MAPE     sMAPE             model  \\\n",
      "0  0.989342  0.988703  8.131789  8.186339      RandomForest   \n",
      "1  0.986882  0.986226  8.872725  9.018178  GradientBoosting   \n",
      "\n",
      "                                         best_params  search_time  fit_time  \n",
      "0  {'n_estimators': 75, 'max_depth': 10, 'min_sam...    31.614191  0.220056  \n",
      "1  {'n_estimators': 200, 'learning_rate': 0.15000...   253.428339  0.772739  \n",
      "\n",
      "Risultati test set salvati in 'results/stat/test_set_results_stat.csv' e 'results/stat/test_set_results_stat.pkl'\n",
      "Dataset shape: (1095, 8)\n",
      "\n",
      "Columns: ['date', 'slp', 'day_of_year', 'apparent_temperature_mean', 'temperature_2m_mean', 'apparent_temperature_max', 'temperature_2m_max', 'sunrise']\n",
      "\n",
      "============================================================\n",
      "Inizio ricerca per: RandomForest\n",
      "Coarse grid size: 108 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of 108 | elapsed:    2.6s remaining:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of 108 | elapsed:    3.0s remaining:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of 108 | elapsed:    3.2s remaining:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 108 | elapsed:    5.0s remaining:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 108 | elapsed:    5.3s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 108 | elapsed:    5.5s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 108 | elapsed:    5.8s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 108 | elapsed:    9.2s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 108 | elapsed:    9.3s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 108 | elapsed:    9.8s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-2.5269 — params={'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'max_features': 'sqrt'}\n",
      "  R2=-2.5269 — params={'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'max_features': 'log2'}\n",
      "  R2=-2.5554 — params={'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "\n",
      "Fine grid size (limitata): 2058 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 617 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 701 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 789 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 881 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 928 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 977 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1077 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1181 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1289 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1401 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1458 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1517 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1637 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1698 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1761 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1824 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2041 out of 2058 | elapsed:  4.1min remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2058 out of 2058 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-1.7765 — params={'n_estimators': 200, 'max_depth': 11, 'min_samples_split': 2, 'max_features': 0.2}\n",
      "  R2=-1.7765 — params={'n_estimators': 200, 'max_depth': 11, 'min_samples_split': 2, 'max_features': 0.3}\n",
      "  R2=-1.8394 — params={'n_estimators': 150, 'max_depth': 11, 'min_samples_split': 2, 'max_features': 0.3}\n",
      "Risultati salvati in results/rf/results_RandomForest_coarse_to_fine_rf.pkl\n",
      "\n",
      "============================================================\n",
      "Inizio ricerca per: GradientBoosting\n",
      "Coarse grid size: 81 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  81 | elapsed:    1.2s remaining:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  81 | elapsed:    1.8s remaining:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  81 | elapsed:    2.3s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  81 | elapsed:    4.4s remaining:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  81 | elapsed:    5.4s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  81 | elapsed:    6.3s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  81 | elapsed:   10.0s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  81 | elapsed:   11.7s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  81 | elapsed:   13.9s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   17.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-4.1399 — params={'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.6}\n",
      "  R2=-4.1405 — params={'n_estimators': 800, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.6}\n",
      "  R2=-4.1566 — params={'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 0.6}\n",
      "\n",
      "Fine grid size (limitata): 2401 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 617 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 701 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 789 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 881 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 928 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done 977 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1077 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1181 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1289 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1401 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1458 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1517 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1637 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1698 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1761 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1824 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1889 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2021 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2088 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2157 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2401 out of 2401 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-3.5226 — params={'n_estimators': 250, 'learning_rate': np.float64(0.08333333333333334), 'max_depth': 10, 'subsample': np.float64(0.3)}\n",
      "  R2=-3.5298 — params={'n_estimators': 300, 'learning_rate': np.float64(0.13333333333333336), 'max_depth': 8, 'subsample': np.float64(0.3)}\n",
      "  R2=-3.5387 — params={'n_estimators': 200, 'learning_rate': np.float64(0.13333333333333336), 'max_depth': 8, 'subsample': np.float64(0.3)}\n",
      "Risultati salvati in results/rf/results_GradientBoosting_coarse_to_fine_rf.pkl\n",
      "\n",
      "================================================================================\n",
      "CONFRONTO FINALE: modelli ottimizzati\n",
      "              model  search_time   R2_mean      RMSE_mean       MAE_mean  \\\n",
      "0      RandomForest   256.706529 -1.776504  178091.860426  145217.034567   \n",
      "1  GradientBoosting   197.330156 -3.522570  180649.333017  144916.773736   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 200, 'max_depth': 11, 'min_sa...  \n",
      "1  {'n_estimators': 250, 'learning_rate': 0.08333...  \n",
      "\n",
      "Fit e salvataggio dei modelli finali (su tutto il dataset):\n",
      "  Fit model: RandomForest con params: {'n_estimators': 200, 'max_depth': 11, 'min_samples_split': 2, 'max_features': 0.2}\n",
      "  Salvato: results/rf/best_model_RandomForest_rf.pkl\n",
      "  Fit model: GradientBoosting con params: {'n_estimators': 250, 'learning_rate': np.float64(0.08333333333333334), 'max_depth': 10, 'subsample': np.float64(0.3)}\n",
      "  Salvato: results/rf/best_model_GradientBoosting_rf.pkl\n",
      "\n",
      "DONE\n",
      "[{'R2': 0.9744156510718605, 'RMSE': np.float64(110080.97130026315), 'MAE': 74173.92315968795, 'Bias': np.float64(-26667.358144420697), 'Max_Error': np.float64(594259.0712007196), 'Pearson': np.float64(0.988374075386242), 'Spearman': np.float64(0.9869227561120669), 'MAPE': np.float64(9.128070718106349), 'sMAPE': np.float64(9.079987973968038), 'model': 'RandomForest', 'best_params': {'n_estimators': 200, 'max_depth': 11, 'min_samples_split': 2, 'max_features': 0.2}, 'search_time': 256.70652866363525, 'fit_time': 0.6724967956542969}, {'R2': 0.973846546166814, 'RMSE': np.float64(111298.57224785477), 'MAE': 73346.35306512701, 'Bias': np.float64(-20931.78502651683), 'Max_Error': np.float64(587146.4145919045), 'Pearson': np.float64(0.9873063625072465), 'Spearman': np.float64(0.9863642981765597), 'MAPE': np.float64(8.732476522670707), 'sMAPE': np.float64(8.897277397261618), 'model': 'GradientBoosting', 'best_params': {'n_estimators': 250, 'learning_rate': np.float64(0.08333333333333334), 'max_depth': 10, 'subsample': np.float64(0.3)}, 'search_time': 197.3301558494568, 'fit_time': 0.38859009742736816}]\n",
      "\n",
      "=== Risultati sui test set ===\n",
      "         R2           RMSE           MAE          Bias      Max_Error  \\\n",
      "0  0.974416  110080.971300  74173.923160 -26667.358144  594259.071201   \n",
      "1  0.973847  111298.572248  73346.353065 -20931.785027  587146.414592   \n",
      "\n",
      "    Pearson  Spearman      MAPE     sMAPE             model  \\\n",
      "0  0.988374  0.986923  9.128071  9.079988      RandomForest   \n",
      "1  0.987306  0.986364  8.732477  8.897277  GradientBoosting   \n",
      "\n",
      "                                         best_params  search_time  fit_time  \n",
      "0  {'n_estimators': 200, 'max_depth': 11, 'min_sa...   256.706529  0.672497  \n",
      "1  {'n_estimators': 250, 'learning_rate': 0.08333...   197.330156  0.388590  \n",
      "\n",
      "Risultati test set salvati in 'results/rf/test_set_results_rf.csv' e 'results/rf/test_set_results_rf.pkl'\n"
     ]
    }
   ],
   "source": [
    "for data_name in data_names:\n",
    "    fine_tune_pipeline(data_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
