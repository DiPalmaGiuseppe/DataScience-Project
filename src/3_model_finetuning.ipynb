{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0eed87",
   "metadata": {},
   "source": [
    "# Model Selection for SLP Prediction\n",
    "\n",
    "This notebook performs model selection to predict the `slp` column using various machine learning algorithms with time series cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import clone\n",
    "from lightgbm import LGBMRegressor\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05222b9e",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253b1834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1095, 13)\n",
      "\n",
      "Columns: ['date', 'slp', 'temperature_2m_mean', 'sunrise', 'et0_fao_evapotranspiration', 'sunshine_duration', 'snowfall_sum', 'day_of_year', 'precipitation_hours', 'weathercode', 'windspeed_10m_max', 'rain_sum', 'holiday']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>slp</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>weathercode</th>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>693745.937</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.132183</td>\n",
       "      <td>-0.551434</td>\n",
       "      <td>-0.944343</td>\n",
       "      <td>-0.160809</td>\n",
       "      <td>274</td>\n",
       "      <td>0.480580</td>\n",
       "      <td>61</td>\n",
       "      <td>0.697061</td>\n",
       "      <td>0.969397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>633340.108</td>\n",
       "      <td>0.204324</td>\n",
       "      <td>0.143013</td>\n",
       "      <td>-0.204844</td>\n",
       "      <td>0.522740</td>\n",
       "      <td>-0.160809</td>\n",
       "      <td>275</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>55</td>\n",
       "      <td>1.031850</td>\n",
       "      <td>0.126311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>621820.506</td>\n",
       "      <td>0.217724</td>\n",
       "      <td>0.164674</td>\n",
       "      <td>-0.359572</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>-0.160809</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.763233</td>\n",
       "      <td>3</td>\n",
       "      <td>1.398524</td>\n",
       "      <td>-0.475894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-04</td>\n",
       "      <td>549282.563</td>\n",
       "      <td>0.271326</td>\n",
       "      <td>0.186334</td>\n",
       "      <td>-0.396706</td>\n",
       "      <td>0.014750</td>\n",
       "      <td>-0.160809</td>\n",
       "      <td>277</td>\n",
       "      <td>-0.763233</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.514557</td>\n",
       "      <td>-0.475894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>483362.562</td>\n",
       "      <td>0.485730</td>\n",
       "      <td>0.207995</td>\n",
       "      <td>0.024153</td>\n",
       "      <td>0.337364</td>\n",
       "      <td>-0.160809</td>\n",
       "      <td>278</td>\n",
       "      <td>-0.763233</td>\n",
       "      <td>3</td>\n",
       "      <td>0.314445</td>\n",
       "      <td>-0.475894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         slp  temperature_2m_mean   sunrise  \\\n",
       "0  2022-10-01  693745.937             0.030121  0.132183   \n",
       "1  2022-10-02  633340.108             0.204324  0.143013   \n",
       "2  2022-10-03  621820.506             0.217724  0.164674   \n",
       "3  2022-10-04  549282.563             0.271326  0.186334   \n",
       "4  2022-10-05  483362.562             0.485730  0.207995   \n",
       "\n",
       "   et0_fao_evapotranspiration  sunshine_duration  snowfall_sum  day_of_year  \\\n",
       "0                   -0.551434          -0.944343     -0.160809          274   \n",
       "1                   -0.204844           0.522740     -0.160809          275   \n",
       "2                   -0.359572          -0.105130     -0.160809          276   \n",
       "3                   -0.396706           0.014750     -0.160809          277   \n",
       "4                    0.024153           0.337364     -0.160809          278   \n",
       "\n",
       "   precipitation_hours  weathercode  windspeed_10m_max  rain_sum  holiday  \n",
       "0             0.480580           61           0.697061  0.969397        0  \n",
       "1             0.065976           55           1.031850  0.126311        0  \n",
       "2            -0.763233            3           1.398524 -0.475894        1  \n",
       "3            -0.763233            3          -0.514557 -0.475894        0  \n",
       "4            -0.763233            3           0.314445 -0.475894        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_name = 'stat'\n",
    "out_path = f'results/{data_name}'\n",
    "dataset = f'dataset/data_v3_{data_name}.csv'\n",
    "df = pd.read_csv(dataset, sep=';', decimal=',')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b918bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date and sort by date (important for time series)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ad8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "\n",
    "X = df.drop(columns=['date', 'slp'])\n",
    "y = df['slp']\n",
    "\n",
    "# Define feature types for proper preprocessing\n",
    "boolean_cols = ['holiday']\n",
    "categorical_cols = ['weathercode']  # Leave as-is for tree-based models\n",
    "cyclical_cols = ['day_of_week', 'day_of_year', 'winddirection_10m_dominant']\n",
    "\n",
    "# All other columns are continuous and should be scaled\n",
    "continuous_cols = [col for col in X.columns \n",
    "                   if col not in boolean_cols + categorical_cols + cyclical_cols]\n",
    "\n",
    "test_days = 365\n",
    "X_test = X.iloc[-test_days:]\n",
    "y_test = y.iloc[-test_days:]\n",
    "\n",
    "X_train = X.iloc[:-test_days]\n",
    "y_train = y.iloc[:-test_days]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063a7cc",
   "metadata": {},
   "source": [
    "## 3. Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c74604",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 10\n",
    "tscv = TimeSeriesSplit(n_splits = n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7720c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_params(estimator, X, y, tscv):\n",
    "    \"\"\"Valuta un singolo estimator (clonato) con TimeSeriesSplit.\n",
    "    Ritorna dizionario di metriche medie.\n",
    "    \"\"\"\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model = clone(estimator)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    return {\n",
    "        'RMSE_mean': np.mean(rmse_scores),\n",
    "        'RMSE_std': np.std(rmse_scores),\n",
    "        'MAE_mean': np.mean(mae_scores),\n",
    "        'MAE_std': np.std(mae_scores),\n",
    "        'R2_mean': np.mean(r2_scores),\n",
    "        'R2_std': np.std(r2_scores),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e6b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_iter(grid_dict):\n",
    "    \"\"\"Genera tutte le combinazioni dalla dict di liste come sklearn.model_selection.ParameterGrid.\n",
    "    grid_dict: {'param': [v1,v2,...], ...}\n",
    "    \"\"\"\n",
    "    keys = list(grid_dict.keys())\n",
    "    for values in itertools.product(*(grid_dict[k] for k in keys)):\n",
    "        yield dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a0b0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_results(results_list, k=5, metric='R2_mean'):\n",
    "    \"\"\"Ordina la lista di dict (ognuno con 'params' e metriche) e ritorna top k.\n",
    "    metric: campo su cui ordinare (default R2_mean decrescente).\n",
    "    \"\"\"\n",
    "    return sorted(results_list, key=lambda r: r.get(metric, -np.inf), reverse=True)[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f3197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fine_grid_around(best_params, param_specs, factor=0.5, n_points=5):\n",
    "    \"\"\"Crea una lista di param dict per la fine search intorno ai best_params.\n",
    "    param_specs for each param: {'type':'int'/'float'/'cat', 'bounds':(min,max)}\n",
    "    factor: estensione percentuale (es 0.5 = +/-50%)\n",
    "    n_points: quanti punti generare per ogni parametro\n",
    "    \"\"\"\n",
    "    fine_specs = {}\n",
    "    for p, spec in param_specs.items():\n",
    "        best = best_params.get(p, None)\n",
    "        if best is None:\n",
    "            # se non presente, usa bounds\n",
    "            lo, hi = spec.get('bounds', (None, None))\n",
    "            if spec['type'] == 'cat':\n",
    "                fine_specs[p] = spec['values']\n",
    "            elif spec['type'] == 'int':\n",
    "                fine_specs[p] = list(range(\n",
    "                    max(1, int(lo)),\n",
    "                    int(hi) + 1,\n",
    "                    max(1, int((int(hi)-int(lo))//(n_points-1) if n_points>1 else 1))\n",
    "                ))\n",
    "            else:\n",
    "                fine_specs[p] = list(np.linspace(lo, hi, n_points))\n",
    "            continue\n",
    "\n",
    "        if spec['type'] == 'cat':\n",
    "            fine_specs[p] = spec['values']\n",
    "\n",
    "        elif spec['type'] == 'int':\n",
    "            lo = max(spec['bounds'][0], int(best - max(1, factor * best)))\n",
    "            hi = min(spec['bounds'][1], int(best + max(1, factor * best)))\n",
    "            if lo >= hi:\n",
    "                fine_specs[p] = [int(best)]\n",
    "            else:\n",
    "                fine_specs[p] = sorted(list(set([int(x) for x in np.linspace(lo, hi, n_points)])))\n",
    "\n",
    "        else:  # float\n",
    "            lo = max(spec['bounds'][0], best * (1 - factor))\n",
    "            hi = min(spec['bounds'][1], best * (1 + factor))\n",
    "            fine_specs[p] = list(np.linspace(lo, hi, n_points))\n",
    "\n",
    "    combos = list(itertools.islice(param_grid_iter(fine_specs), 10000))\n",
    "    return combos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d00bd",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded42873",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_space = {\n",
    "    'RandomForest': {\n",
    "        'estimator': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        'coarse': {\n",
    "            'n_estimators': [50, 100, 300],\n",
    "            'max_depth': [5, 10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['sqrt', 'log2', 0.5]\n",
    "        },\n",
    "        'specs': {\n",
    "            'n_estimators': {'type':'int', 'bounds':(10,1000)},\n",
    "            'max_depth': {'type':'int', 'bounds':(3,50)},\n",
    "            'min_samples_split': {'type':'int', 'bounds':(2,50)},\n",
    "            'max_features': {'type':'cat', 'values':['sqrt','log2',0.2,0.3,0.4,0.5,None]}\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'estimator': GradientBoostingRegressor(random_state=42),\n",
    "        'coarse': {\n",
    "            'n_estimators': [100, 300, 800],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 8],\n",
    "            'subsample': [0.6, 0.8, 1.0]\n",
    "        },\n",
    "        'specs': {\n",
    "            'n_estimators': {'type':'int', 'bounds':(50,2000)},\n",
    "            'learning_rate': {'type':'float', 'bounds':(1e-4,1.0)},\n",
    "            'max_depth': {'type':'int', 'bounds':(1,20)},\n",
    "            'subsample': {'type':'float', 'bounds':(0.3,1.0)}\n",
    "        }\n",
    "    },\n",
    "    # 'LightGBM': {\n",
    "    #     'estimator': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    #     'coarse': {\n",
    "    #         'n_estimators': [100, 300, 1000],\n",
    "    #         'learning_rate': [0.01, 0.05, 0.1],\n",
    "    #         'num_leaves': [15, 31, 63],\n",
    "    #         'max_depth': [-1, 5, 10]\n",
    "    #     },\n",
    "    #     'specs': {\n",
    "    #         'n_estimators': {'type':'int', 'bounds':(50,3000)},\n",
    "    #         'learning_rate': {'type':'float', 'bounds':(1e-4,1.0)},\n",
    "    #         'num_leaves': {'type':'int', 'bounds':(6,2048)},\n",
    "    #         'max_depth': {'type':'int', 'bounds':(-1,50)},\n",
    "    #         'min_child_samples': {'type':'int', 'bounds':(1,100)}\n",
    "    #     }\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8ff1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_param_set(estimator, params, X, y, tscv):\n",
    "    est = clone(estimator).set_params(**params)\n",
    "    metrics = evaluate_model_params(est, X, y, tscv)\n",
    "    return {'params': params, **metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417a560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_to_fine_search(name, model_info, X, y, tscv, top_k=5):\n",
    "    print('\\n' + '='*60)\n",
    "    print(f'Inizio ricerca per: {name}')\n",
    "    estimator = model_info['estimator']\n",
    "    coarse_grid = model_info['coarse']\n",
    "    specs = model_info['specs']\n",
    "\n",
    "    # ------- COARSE SEARCH PARALLEL -------\n",
    "    param_list = list(param_grid_iter(coarse_grid))\n",
    "    print(f'Coarse grid size: {len(param_list)} combinazioni')\n",
    "\n",
    "    coarse_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(evaluate_param_set)(estimator, params, X, y, tscv)\n",
    "        for params in param_list\n",
    "    )\n",
    "\n",
    "    # top-k\n",
    "    top_coarse = top_k_results(coarse_results, k=top_k, metric='R2_mean')\n",
    "    print('\\nTop risultati (coarse):')\n",
    "    for r in top_coarse:\n",
    "        print(f\"  R2={r['R2_mean']:.4f} — params={r['params']}\")\n",
    "\n",
    "    # ------- FINE SEARCH PARALLEL -------\n",
    "    best_coarse = top_coarse[0]\n",
    "    best_params = best_coarse['params']\n",
    "\n",
    "    fine_param_list = make_fine_grid_around(best_params, specs, factor=0.5, n_points=7)\n",
    "    print(f\"\\nFine grid size (limitata): {len(fine_param_list)} combinazioni\\n\")\n",
    "\n",
    "    fine_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(evaluate_param_set)(estimator, params, X, y, tscv)\n",
    "        for params in fine_param_list\n",
    "    )\n",
    "\n",
    "    top_fine = top_k_results(fine_results, k=3, metric='R2_mean')\n",
    "    print('\\nTop risultati (fine):')\n",
    "    for r in top_fine:\n",
    "        print(f\"  R2={r['R2_mean']:.4f} — params={r['params']}\")\n",
    "\n",
    "    best_final = top_fine[0]\n",
    "    return {\n",
    "        'coarse_results': coarse_results,\n",
    "        'top_coarse': top_coarse,\n",
    "        'fine_results': fine_results,\n",
    "        'top_fine': top_fine,\n",
    "        'best': best_final\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5949c065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Inizio ricerca per: RandomForest\n",
      "Coarse grid size: 108 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of 108 | elapsed:    5.4s remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of 108 | elapsed:    5.6s remaining:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of 108 | elapsed:    5.7s remaining:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of 108 | elapsed:    7.0s remaining:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of 108 | elapsed:    7.1s remaining:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of 108 | elapsed:    7.2s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of 108 | elapsed:    7.4s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 108 | elapsed:   10.5s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  94 out of 108 | elapsed:   10.5s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 108 | elapsed:   10.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-6.1651 — params={'n_estimators': 50, 'max_depth': None, 'min_samples_split': 2, 'max_features': 0.5}\n",
      "  R2=-6.1668 — params={'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 2, 'max_features': 0.5}\n",
      "  R2=-6.2868 — params={'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2, 'max_features': 0.5}\n",
      "\n",
      "Fine grid size (limitata): 686 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 532 out of 686 | elapsed:   16.5s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 601 out of 686 | elapsed:   19.6s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 670 out of 686 | elapsed:   21.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 686 out of 686 | elapsed:   21.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-5.9841 — params={'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 3, 'max_features': None}\n",
      "  R2=-6.0380 — params={'n_estimators': 58, 'max_depth': 10, 'min_samples_split': 2, 'max_features': None}\n",
      "  R2=-6.0869 — params={'n_estimators': 41, 'max_depth': 10, 'min_samples_split': 2, 'max_features': None}\n",
      "Risultati salvati in results/stat/results_RandomForest_coarse_to_fine_stat.pkl\n",
      "\n",
      "============================================================\n",
      "Inizio ricerca per: GradientBoosting\n",
      "Coarse grid size: 81 combinazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of  81 | elapsed:    1.4s remaining:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  81 | elapsed:    2.1s remaining:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  81 | elapsed:    2.8s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  81 | elapsed:    4.2s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  81 | elapsed:    5.5s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  81 | elapsed:    6.7s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  81 | elapsed:    9.8s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  81 | elapsed:   12.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  81 | elapsed:   15.0s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 112 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (coarse):\n",
      "  R2=-4.0370 — params={'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0}\n",
      "  R2=-4.0370 — params={'n_estimators': 800, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0}\n",
      "  R2=-4.0382 — params={'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 8, 'subsample': 1.0}\n",
      "\n",
      "Fine grid size (limitata): 2401 combinazioni\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 617 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 701 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 789 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 881 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 928 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 977 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1077 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1181 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1289 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1401 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1458 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1517 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1637 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1698 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1761 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1824 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1889 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2021 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2088 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2157 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2401 out of 2401 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top risultati (fine):\n",
      "  R2=-3.6828 — params={'n_estimators': 350, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 6, 'subsample': np.float64(0.5)}\n",
      "  R2=-3.6829 — params={'n_estimators': 450, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 6, 'subsample': np.float64(0.5)}\n",
      "  R2=-3.6830 — params={'n_estimators': 400, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 6, 'subsample': np.float64(0.5)}\n",
      "Risultati salvati in results/stat/results_GradientBoosting_coarse_to_fine_stat.pkl\n"
     ]
    }
   ],
   "source": [
    "all_best = {}\n",
    "for name, info in models_space.items():\n",
    "    res = coarse_to_fine_search(name, info, X_train, y_train, tscv, top_k=3)\n",
    "    best_entry = res['best']\n",
    "    all_best[name] = best_entry\n",
    "    # salva i risultati intermedi su disco per controllo laterale\n",
    "    joblib.dump(res, f'{out_path}/results_{name}_coarse_to_fine_{data_name}.pkl')\n",
    "    print(f\"Risultati salvati in {out_path}/results_{name}_coarse_to_fine_{data_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28777418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONFRONTO FINALE: modelli ottimizzati\n",
      "              model   R2_mean      RMSE_mean       MAE_mean  \\\n",
      "0  GradientBoosting -3.682819  200385.396284  164186.833704   \n",
      "1      RandomForest -5.984121  208557.535249  171783.291551   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 350, 'learning_rate': 0.15000...  \n",
      "1  {'n_estimators': 75, 'max_depth': 10, 'min_sam...  \n"
     ]
    }
   ],
   "source": [
    "summary = []\n",
    "for name, best in all_best.items():\n",
    "    summary.append({\n",
    "        'model': name,\n",
    "        'R2_mean': best['R2_mean'],\n",
    "        'RMSE_mean': best['RMSE_mean'],\n",
    "        'MAE_mean': best['MAE_mean'],\n",
    "        'best_params': best['params']\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary).sort_values('R2_mean', ascending=False).reset_index(drop=True)\n",
    "print('\\n' + '='*80)\n",
    "print('CONFRONTO FINALE: modelli ottimizzati')\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9816c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit e salvataggio dei modelli finali (su tutto il dataset):\n",
      "  Fit model: GradientBoosting con params: {'n_estimators': 350, 'learning_rate': np.float64(0.15000000000000002), 'max_depth': 6, 'subsample': np.float64(0.5)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Salvato: results/stat/best_model_GradientBoosting_stat.pkl\n",
      "  Fit model: RandomForest con params: {'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 3, 'max_features': None}\n",
      "  Salvato: results/stat/best_model_RandomForest_stat.pkl\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print('\\nFit e salvataggio dei modelli finali (su tutto il dataset):')\n",
    "for idx, row in summary_df.iterrows():\n",
    "    name = row['model']\n",
    "    best_params = row['best_params']\n",
    "    estimator = models_space[name]['estimator'].set_params(**best_params)\n",
    "    print(f\"  Fit model: {name} con params: {best_params}\")\n",
    "    estimator.fit(X_train, y_train)\n",
    "    joblib.dump(estimator, f'{out_path}/best_model_{name}_{data_name}.pkl')\n",
    "    print(f\"  Salvato: {out_path}/best_model_{name}_{data_name}.pkl\")\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b0d495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(estimator, X_test, y_test):\n",
    "    \"\"\"Valuta un modello già fit su un test set con metriche aggiuntive.\"\"\"\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    bias = np.mean(y_pred - y_test)\n",
    "    max_error = np.max(np.abs(y_pred - y_test))\n",
    "    pearson_corr = pearsonr(y_test, y_pred)[0]\n",
    "    spearman_corr = spearmanr(y_test, y_pred)[0]\n",
    "    mape = np.mean(np.abs((y_test - y_pred)/y_test)) * 100  # attenzione valori vicino a zero\n",
    "    smape = np.mean(np.abs(y_test - y_pred)/((np.abs(y_test)+np.abs(y_pred))/2)) * 100\n",
    "    \n",
    "    return {\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'Bias': bias,\n",
    "        'Max_Error': max_error,\n",
    "        'Pearson': pearson_corr,\n",
    "        'Spearman': spearman_corr,\n",
    "        'MAPE': mape,\n",
    "        'sMAPE': smape\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd096e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Risultati sui test set ===\n",
      "         R2           RMSE           MAE          Bias     Max_Error  \\\n",
      "0  0.977886  102342.387311  67609.947432 -19923.536554  494618.51268   \n",
      "1  0.974090  110779.547178  73721.649296 -20068.810195  492312.89677   \n",
      "\n",
      "    Pearson  Spearman      MAPE     sMAPE             model  \\\n",
      "0  0.989354  0.988690  8.124447  8.176765      RandomForest   \n",
      "1  0.987412  0.986331  8.759123  8.969314  GradientBoosting   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'n_estimators': 75, 'max_depth': 10, 'min_sam...  \n",
      "1  {'n_estimators': 350, 'learning_rate': 0.15000...  \n"
     ]
    }
   ],
   "source": [
    "test_results = []\n",
    "\n",
    "for idx, row in summary_df.iterrows():\n",
    "    name = row['model']\n",
    "    model_file = f'{out_path}/best_model_{name}_{data_name}.pkl'\n",
    "    \n",
    "    # Carica modello già fit\n",
    "    model = joblib.load(model_file)\n",
    "    \n",
    "    # Valutazione sul test set\n",
    "    metrics = evaluate_on_test(model, X_test, y_test)\n",
    "    \n",
    "    metrics['model'] = name\n",
    "    metrics['best_params'] = row['best_params']\n",
    "    test_results.append(metrics)\n",
    "\n",
    "# Trasforma in DataFrame\n",
    "test_results_df = pd.DataFrame(test_results).sort_values('R2', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Stampa\n",
    "print('\\n=== Risultati sui test set ===')\n",
    "print(test_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b4b1671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risultati test set salvati in 'results/stat/test_set_results_stat.csv' e 'results/stat/test_set_results_stat.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Salva in CSV\n",
    "test_results_df.to_csv(f'{out_path}/test_set_results_{data_name}.csv', index=False)\n",
    "\n",
    "# Salva anche in pickle per uso successivo\n",
    "joblib.dump(test_results_df, f'{out_path}/test_set_results_{data_name}.pkl')\n",
    "\n",
    "print(f\"\\nRisultati test set salvati in '{out_path}/test_set_results_{data_name}.csv' e '{out_path}/test_set_results_{data_name}.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
