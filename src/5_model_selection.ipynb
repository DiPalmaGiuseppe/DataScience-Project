{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0eed87",
   "metadata": {},
   "source": [
    "# Model Selection for SLP Prediction\n",
    "\n",
    "This notebook performs model selection to predict the `slp` column using various machine learning algorithms with time series cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05222b9e",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "253b1834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3560, 26)\n",
      "\n",
      "Columns: ['date', 'entry', 'rlm', 'slp', 'day_of_year', 'day_of_week', 'holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'winddirection_10m_dominant', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>entry</th>\n",
       "      <th>rlm</th>\n",
       "      <th>slp</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weathercode</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>...</th>\n",
       "      <th>daylight_duration</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <th>windgusts_10m_max</th>\n",
       "      <th>winddirection_10m_dominant</th>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00+00:00</td>\n",
       "      <td>4.501250e+06</td>\n",
       "      <td>2.565526e+06</td>\n",
       "      <td>1.935724e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>27973.34</td>\n",
       "      <td>17706.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>208</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02 00:00:00+00:00</td>\n",
       "      <td>5.448037e+06</td>\n",
       "      <td>3.037879e+06</td>\n",
       "      <td>2.410158e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>28047.14</td>\n",
       "      <td>2501.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.2</td>\n",
       "      <td>97</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03 00:00:00+00:00</td>\n",
       "      <td>6.472305e+06</td>\n",
       "      <td>3.462336e+06</td>\n",
       "      <td>3.009970e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>...</td>\n",
       "      <td>28127.21</td>\n",
       "      <td>21285.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>44.3</td>\n",
       "      <td>102</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:00:00+00:00</td>\n",
       "      <td>7.766598e+06</td>\n",
       "      <td>4.565146e+06</td>\n",
       "      <td>3.201452e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>28213.34</td>\n",
       "      <td>9701.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>39.2</td>\n",
       "      <td>97</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05 00:00:00+00:00</td>\n",
       "      <td>7.842385e+06</td>\n",
       "      <td>4.672447e+06</td>\n",
       "      <td>3.169938e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>28305.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>33.5</td>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date         entry           rlm           slp  \\\n",
       "0  2016-01-01 00:00:00+00:00  4.501250e+06  2.565526e+06  1.935724e+06   \n",
       "1  2016-01-02 00:00:00+00:00  5.448037e+06  3.037879e+06  2.410158e+06   \n",
       "2  2016-01-03 00:00:00+00:00  6.472305e+06  3.462336e+06  3.009970e+06   \n",
       "3  2016-01-04 00:00:00+00:00  7.766598e+06  4.565146e+06  3.201452e+06   \n",
       "4  2016-01-05 00:00:00+00:00  7.842385e+06  4.672447e+06  3.169938e+06   \n",
       "\n",
       "   day_of_year  day_of_week  holiday  weathercode temperature_2m_max  \\\n",
       "0            1            4        1            3                4.3   \n",
       "1            2            5        0            3                2.5   \n",
       "2            3            6        0            3               -5.4   \n",
       "3            4            0        0            3               -3.5   \n",
       "4            5            1        0           73               -5.2   \n",
       "\n",
       "  temperature_2m_min  ... daylight_duration sunshine_duration rain_sum  \\\n",
       "0                0.1  ...          27973.34          17706.46      0.0   \n",
       "1               -5.3  ...          28047.14           2501.06      0.0   \n",
       "2               -8.4  ...          28127.21          21285.25      0.0   \n",
       "3               -7.9  ...          28213.34            9701.3      0.0   \n",
       "4               -6.4  ...          28305.35               0.0      0.0   \n",
       "\n",
       "  snowfall_sum  precipitation_hours  windspeed_10m_max windgusts_10m_max  \\\n",
       "0          0.0                  0.0                9.0              18.4   \n",
       "1          0.0                  0.0               24.0              48.2   \n",
       "2          0.0                  0.0               21.5              44.3   \n",
       "3          0.0                  0.0               18.9              39.2   \n",
       "4         2.45                 14.0               16.2              33.5   \n",
       "\n",
       "  winddirection_10m_dominant shortwave_radiation_sum  \\\n",
       "0                        208                    2.64   \n",
       "1                         97                    1.34   \n",
       "2                        102                    3.38   \n",
       "3                         97                    2.47   \n",
       "4                         84                     1.0   \n",
       "\n",
       "  et0_fao_evapotranspiration  \n",
       "0                       0.21  \n",
       "1                        0.5  \n",
       "2                       0.68  \n",
       "3                       0.61  \n",
       "4                       0.46  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset/data_v2_full.csv', sep=';', decimal=',')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d190b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: ['rlm', 'entry']\n",
      "Dataset shape after removing rlm and entry (if present): (3560, 24)\n",
      "\n",
      "Remaining columns: ['date', 'slp', 'day_of_year', 'day_of_week', 'holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'winddirection_10m_dominant', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration']\n"
     ]
    }
   ],
   "source": [
    "# Remove 'rlm' and/or 'entry' columns if present\n",
    "to_remove = [col for col in ['rlm', 'entry'] if col in df.columns]\n",
    "if to_remove:\n",
    "    df_clean = df.drop(columns=to_remove)\n",
    "    print(f\"Removed columns: {to_remove}\")\n",
    "else:\n",
    "    df_clean = df.copy()\n",
    "    print(\"Columns 'rlm' and 'entry' not found, dataset unchanged.\")\n",
    "\n",
    "print(f\"Dataset shape after removing rlm and entry (if present): {df_clean.shape}\")\n",
    "print(f\"\\nRemaining columns: {df_clean.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b918bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date and sort by date (important for time series)\n",
    "df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "df_clean = df_clean.sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770274c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (3560, 22)\n",
      "Target shape: (3560,)\n",
      "\n",
      "Boolean columns (not scaled): ['holiday']\n",
      "Categorical columns (not scaled): ['weathercode']\n",
      "Cyclical columns (will be sin/cos encoded): ['day_of_week', 'day_of_year', 'winddirection_10m_dominant']\n",
      "Continuous columns (will be scaled): ['temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration']\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df_clean.drop(columns=['date', 'slp'])\n",
    "y = df_clean['slp']\n",
    "\n",
    "# Define feature types for proper preprocessing\n",
    "boolean_cols = ['holiday']\n",
    "categorical_cols = ['weathercode']  # Leave as-is for tree-based models\n",
    "cyclical_cols = ['day_of_week', 'day_of_year', 'winddirection_10m_dominant']\n",
    "\n",
    "# All other columns are continuous and should be scaled\n",
    "continuous_cols = [col for col in X.columns \n",
    "                   if col not in boolean_cols + categorical_cols + cyclical_cols]\n",
    "\n",
    "# Convert continuous columns to numeric (CSV has mixed decimal formats: some use ',' some use '.')\n",
    "for col in continuous_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nBoolean columns (not scaled): {boolean_cols}\")\n",
    "print(f\"Categorical columns (not scaled): {categorical_cols}\")\n",
    "print(f\"Cyclical columns (will be sin/cos encoded): {cyclical_cols}\")\n",
    "print(f\"Continuous columns (will be scaled): {continuous_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e5877",
   "metadata": {},
   "source": [
    "## 2. Feature Preprocessing\n",
    "\n",
    "- **Boolean features** (holiday): Left unchanged (0/1)\n",
    "- **Categorical features** (weathercode): Left unchanged (tree-based models handle them well)\n",
    "- **Cyclical features** (day_of_week, day_of_year, winddirection): Sin/cos encoding to preserve circular nature\n",
    "- **Continuous features**: StandardScaler normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0786dd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after cyclical encoding: (3560, 25)\n",
      "\n",
      "New cyclical features added:\n",
      "  day_of_week -> day_of_week_sin, day_of_week_cos\n",
      "  day_of_year -> day_of_year_sin, day_of_year_cos\n",
      "  winddirection_10m_dominant -> winddirection_10m_dominant_sin, winddirection_10m_dominant_cos\n",
      "\n",
      "All features: ['holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration', 'day_of_week_sin', 'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos', 'winddirection_10m_dominant_sin', 'winddirection_10m_dominant_cos']\n"
     ]
    }
   ],
   "source": [
    "# Apply cyclical encoding for cyclical features\n",
    "# This preserves the circular nature of these variables (e.g., day 365 is close to day 1)\n",
    "\n",
    "def cyclical_encode(df, col, max_val):\n",
    "    \"\"\"Encode a cyclical feature using sine and cosine transformation.\"\"\"\n",
    "    df[f'{col}_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "    df[f'{col}_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "    return df\n",
    "\n",
    "# Create a copy and apply cyclical encoding\n",
    "X_encoded = X.copy()\n",
    "\n",
    "# Encode day_of_week (0-6, period=7)\n",
    "X_encoded = cyclical_encode(X_encoded, 'day_of_week', 7)\n",
    "\n",
    "# Encode day_of_year (1-366, period=366)\n",
    "X_encoded = cyclical_encode(X_encoded, 'day_of_year', 366)\n",
    "\n",
    "# Encode wind direction (0-360 degrees, period=360)\n",
    "X_encoded = cyclical_encode(X_encoded, 'winddirection_10m_dominant', 360)\n",
    "\n",
    "# Drop original cyclical columns (replaced by sin/cos versions)\n",
    "X_encoded = X_encoded.drop(columns=cyclical_cols)\n",
    "\n",
    "print(f\"Shape after cyclical encoding: {X_encoded.shape}\")\n",
    "print(f\"\\nNew cyclical features added:\")\n",
    "for col in cyclical_cols:\n",
    "    print(f\"  {col} -> {col}_sin, {col}_cos\")\n",
    "print(f\"\\nAll features: {X_encoded.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c361f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous feature statistics before scaling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <td>-6.70</td>\n",
       "      <td>36.10</td>\n",
       "      <td>14.928006</td>\n",
       "      <td>8.401043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <td>-17.50</td>\n",
       "      <td>23.10</td>\n",
       "      <td>7.235309</td>\n",
       "      <td>6.700360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <td>-10.20</td>\n",
       "      <td>29.10</td>\n",
       "      <td>11.075225</td>\n",
       "      <td>7.463579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <td>-13.00</td>\n",
       "      <td>36.70</td>\n",
       "      <td>12.627893</td>\n",
       "      <td>9.957706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <td>-22.80</td>\n",
       "      <td>23.50</td>\n",
       "      <td>4.740225</td>\n",
       "      <td>8.176099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_mean</th>\n",
       "      <td>-14.70</td>\n",
       "      <td>29.60</td>\n",
       "      <td>8.742556</td>\n",
       "      <td>9.013316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunrise</th>\n",
       "      <td>9960.00</td>\n",
       "      <td>26400.00</td>\n",
       "      <td>17927.696629</td>\n",
       "      <td>5540.841244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset</th>\n",
       "      <td>53760.00</td>\n",
       "      <td>70560.00</td>\n",
       "      <td>62434.162921</td>\n",
       "      <td>5664.918279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight_duration</th>\n",
       "      <td>27607.04</td>\n",
       "      <td>60523.94</td>\n",
       "      <td>44506.771744</td>\n",
       "      <td>11157.694989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunshine_duration</th>\n",
       "      <td>0.00</td>\n",
       "      <td>55333.02</td>\n",
       "      <td>27306.354107</td>\n",
       "      <td>17105.955470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_sum</th>\n",
       "      <td>0.00</td>\n",
       "      <td>39.20</td>\n",
       "      <td>1.580506</td>\n",
       "      <td>3.321599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snowfall_sum</th>\n",
       "      <td>0.00</td>\n",
       "      <td>9.66</td>\n",
       "      <td>0.062253</td>\n",
       "      <td>0.387176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation_hours</th>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>3.681742</td>\n",
       "      <td>4.824554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <td>3.90</td>\n",
       "      <td>57.00</td>\n",
       "      <td>17.427612</td>\n",
       "      <td>6.273484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windgusts_10m_max</th>\n",
       "      <td>10.80</td>\n",
       "      <td>110.50</td>\n",
       "      <td>35.502331</td>\n",
       "      <td>12.865812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <td>0.30</td>\n",
       "      <td>29.23</td>\n",
       "      <td>11.427919</td>\n",
       "      <td>7.919195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8.02</td>\n",
       "      <td>2.170975</td>\n",
       "      <td>1.615968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 min       max          mean           std\n",
       "temperature_2m_max             -6.70     36.10     14.928006      8.401043\n",
       "temperature_2m_min            -17.50     23.10      7.235309      6.700360\n",
       "temperature_2m_mean           -10.20     29.10     11.075225      7.463579\n",
       "apparent_temperature_max      -13.00     36.70     12.627893      9.957706\n",
       "apparent_temperature_min      -22.80     23.50      4.740225      8.176099\n",
       "apparent_temperature_mean     -14.70     29.60      8.742556      9.013316\n",
       "sunrise                      9960.00  26400.00  17927.696629   5540.841244\n",
       "sunset                      53760.00  70560.00  62434.162921   5664.918279\n",
       "daylight_duration           27607.04  60523.94  44506.771744  11157.694989\n",
       "sunshine_duration               0.00  55333.02  27306.354107  17105.955470\n",
       "rain_sum                        0.00     39.20      1.580506      3.321599\n",
       "snowfall_sum                    0.00      9.66      0.062253      0.387176\n",
       "precipitation_hours             0.00     24.00      3.681742      4.824554\n",
       "windspeed_10m_max               3.90     57.00     17.427612      6.273484\n",
       "windgusts_10m_max              10.80    110.50     35.502331     12.865812\n",
       "shortwave_radiation_sum         0.30     29.23     11.427919      7.919195\n",
       "et0_fao_evapotranspiration      0.10      8.02      2.170975      1.615968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature ranges before scaling (continuous features only)\n",
    "print(\"Continuous feature statistics before scaling:\")\n",
    "X_encoded[continuous_cols].describe().T[['min', 'max', 'mean', 'std']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdacc195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature preprocessing summary:\n",
      "  - Boolean features (unchanged): ['holiday']\n",
      "  - Categorical features (unchanged): ['weathercode']\n",
      "  - Cyclical features (sin/cos encoded): ['day_of_week_sin, day_of_week_cos', 'day_of_year_sin, day_of_year_cos', 'winddirection_10m_dominant_sin, winddirection_10m_dominant_cos']\n",
      "  - Continuous features (standardized): 17 columns\n",
      "\n",
      "Final feature matrix shape: (3560, 25)\n",
      "\n",
      "Continuous feature statistics after scaling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <td>-2.574805</td>\n",
       "      <td>2.520517</td>\n",
       "      <td>6.386901e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <td>-3.692157</td>\n",
       "      <td>2.368070</td>\n",
       "      <td>1.596725e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <td>-2.850940</td>\n",
       "      <td>2.415370</td>\n",
       "      <td>-3.193450e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <td>-2.574036</td>\n",
       "      <td>2.417775</td>\n",
       "      <td>-6.386901e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <td>-3.368855</td>\n",
       "      <td>2.294788</td>\n",
       "      <td>6.786082e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_mean</th>\n",
       "      <td>-2.601246</td>\n",
       "      <td>2.314395</td>\n",
       "      <td>-3.193450e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunrise</th>\n",
       "      <td>-1.438196</td>\n",
       "      <td>1.529279</td>\n",
       "      <td>1.916070e-16</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset</th>\n",
       "      <td>-1.531422</td>\n",
       "      <td>1.434615</td>\n",
       "      <td>-5.029685e-16</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight_duration</th>\n",
       "      <td>-1.514838</td>\n",
       "      <td>1.435728</td>\n",
       "      <td>2.794269e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunshine_duration</th>\n",
       "      <td>-1.596531</td>\n",
       "      <td>1.638646</td>\n",
       "      <td>-1.437053e-16</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_sum</th>\n",
       "      <td>-0.475894</td>\n",
       "      <td>11.327311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snowfall_sum</th>\n",
       "      <td>-0.160809</td>\n",
       "      <td>24.792563</td>\n",
       "      <td>1.995907e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation_hours</th>\n",
       "      <td>-0.763233</td>\n",
       "      <td>4.212019</td>\n",
       "      <td>2.195497e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <td>-2.156619</td>\n",
       "      <td>6.308766</td>\n",
       "      <td>3.193450e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windgusts_10m_max</th>\n",
       "      <td>-1.920268</td>\n",
       "      <td>5.830041</td>\n",
       "      <td>6.786082e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <td>-1.405380</td>\n",
       "      <td>2.248282</td>\n",
       "      <td>-1.596725e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <td>-1.281749</td>\n",
       "      <td>3.620026</td>\n",
       "      <td>-6.386901e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 min        max          mean      std\n",
       "temperature_2m_max         -2.574805   2.520517  6.386901e-17  1.00014\n",
       "temperature_2m_min         -3.692157   2.368070  1.596725e-17  1.00014\n",
       "temperature_2m_mean        -2.850940   2.415370 -3.193450e-17  1.00014\n",
       "apparent_temperature_max   -2.574036   2.417775 -6.386901e-17  1.00014\n",
       "apparent_temperature_min   -3.368855   2.294788  6.786082e-17  1.00014\n",
       "apparent_temperature_mean  -2.601246   2.314395 -3.193450e-17  1.00014\n",
       "sunrise                    -1.438196   1.529279  1.916070e-16  1.00014\n",
       "sunset                     -1.531422   1.434615 -5.029685e-16  1.00014\n",
       "daylight_duration          -1.514838   1.435728  2.794269e-17  1.00014\n",
       "sunshine_duration          -1.596531   1.638646 -1.437053e-16  1.00014\n",
       "rain_sum                   -0.475894  11.327311  0.000000e+00  1.00014\n",
       "snowfall_sum               -0.160809  24.792563  1.995907e-17  1.00014\n",
       "precipitation_hours        -0.763233   4.212019  2.195497e-17  1.00014\n",
       "windspeed_10m_max          -2.156619   6.308766  3.193450e-17  1.00014\n",
       "windgusts_10m_max          -1.920268   5.830041  6.786082e-17  1.00014\n",
       "shortwave_radiation_sum    -1.405380   2.248282 -1.596725e-17  1.00014\n",
       "et0_fao_evapotranspiration -1.281749   3.620026 -6.386901e-17  1.00014"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply StandardScaler ONLY to continuous features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Start with the encoded data\n",
    "X_scaled = X_encoded.copy()\n",
    "\n",
    "# Scale only continuous columns\n",
    "X_scaled[continuous_cols] = scaler.fit_transform(X_encoded[continuous_cols])\n",
    "\n",
    "print(\"Feature preprocessing summary:\")\n",
    "print(f\"  - Boolean features (unchanged): {boolean_cols}\")\n",
    "print(f\"  - Categorical features (unchanged): {categorical_cols}\")\n",
    "print(f\"  - Cyclical features (sin/cos encoded): {[f'{c}_sin, {c}_cos' for c in cyclical_cols]}\")\n",
    "print(f\"  - Continuous features (standardized): {len(continuous_cols)} columns\")\n",
    "print(f\"\\nFinal feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"\\nContinuous feature statistics after scaling:\")\n",
    "X_scaled[continuous_cols].describe().T[['min', 'max', 'mean', 'std']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e05e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported preprocessed data to 'dataset/data_v2_step_5.csv'\n",
      "Shape: (3560, 27)\n"
     ]
    }
   ],
   "source": [
    "# Export preprocessed data to CSV\n",
    "export_df = X_scaled.copy()\n",
    "export_df['slp'] = y.values\n",
    "export_df['date'] = df_clean['date'].values\n",
    "\n",
    "# Reorder columns to put date first\n",
    "cols = ['date', 'slp'] + [col for col in export_df.columns if col not in ['date', 'slp']]\n",
    "export_df = export_df[cols]\n",
    "\n",
    "# Save to dataset folder\n",
    "export_df.to_csv('dataset/data_v2_step_5.csv', sep=';', decimal=',', index=False)\n",
    "print(f\"Exported preprocessed data to 'dataset/data_v2_step_5.csv'\")\n",
    "print(f\"Shape: {export_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063a7cc",
   "metadata": {},
   "source": [
    "## 3. Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c74604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series Cross-Validation Splits:\n",
      "==================================================\n",
      "Fold 1:\n",
      "  Train: 2016-01-01 to 2016-11-25 (330 samples)\n",
      "  Test:  2016-11-26 to 2017-10-14 (323 samples)\n",
      "\n",
      "Fold 2:\n",
      "  Train: 2016-01-01 to 2017-10-14 (653 samples)\n",
      "  Test:  2017-10-15 to 2018-09-02 (323 samples)\n",
      "\n",
      "Fold 3:\n",
      "  Train: 2016-01-01 to 2018-09-02 (976 samples)\n",
      "  Test:  2018-09-03 to 2019-07-22 (323 samples)\n",
      "\n",
      "Fold 4:\n",
      "  Train: 2016-01-01 to 2019-07-22 (1299 samples)\n",
      "  Test:  2019-07-23 to 2020-06-09 (323 samples)\n",
      "\n",
      "Fold 5:\n",
      "  Train: 2016-01-01 to 2020-06-09 (1622 samples)\n",
      "  Test:  2020-06-10 to 2021-04-28 (323 samples)\n",
      "\n",
      "Fold 6:\n",
      "  Train: 2016-01-01 to 2021-04-28 (1945 samples)\n",
      "  Test:  2021-04-29 to 2022-03-17 (323 samples)\n",
      "\n",
      "Fold 7:\n",
      "  Train: 2016-01-01 to 2022-03-17 (2268 samples)\n",
      "  Test:  2022-03-18 to 2023-02-03 (323 samples)\n",
      "\n",
      "Fold 8:\n",
      "  Train: 2016-01-01 to 2023-02-03 (2591 samples)\n",
      "  Test:  2023-02-04 to 2023-12-23 (323 samples)\n",
      "\n",
      "Fold 9:\n",
      "  Train: 2016-01-01 to 2023-12-23 (2914 samples)\n",
      "  Test:  2023-12-24 to 2024-11-10 (323 samples)\n",
      "\n",
      "Fold 10:\n",
      "  Train: 2016-01-01 to 2024-11-10 (3237 samples)\n",
      "  Test:  2024-11-11 to 2025-09-30 (323 samples)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use TimeSeriesSplit for proper time series cross-validation\n",
    "# This ensures we always train on past data and test on future data\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Visualize the splits\n",
    "print(\"Time Series Cross-Validation Splits:\")\n",
    "print(\"=\"*50)\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_scaled)):\n",
    "    train_dates = df_clean.iloc[train_idx]['date']\n",
    "    test_dates = df_clean.iloc[test_idx]['date']\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    print(f\"  Train: {train_dates.min().date()} to {train_dates.max().date()} ({len(train_idx)} samples)\")\n",
    "    print(f\"  Test:  {test_dates.min().date()} to {test_dates.max().date()} ({len(test_idx)} samples)\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dcc0a3",
   "metadata": {},
   "source": [
    "## 4. Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5949c065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models to evaluate: 12\n",
      "  - Linear Regression\n",
      "  - Ridge Regression\n",
      "  - Lasso Regression\n",
      "  - ElasticNet\n",
      "  - Decision Tree\n",
      "  - Random Forest\n",
      "  - Gradient Boosting\n",
      "  - AdaBoost\n",
      "  - XGBoost\n",
      "  - LightGBM\n",
      "  - K-Nearest Neighbors\n",
      "  - SVR\n"
     ]
    }
   ],
   "source": [
    "# Define different types of models with standard parameters\n",
    "models = {\n",
    "    # Linear Models\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    \n",
    "    # Tree-based Models\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_jobs=-1, verbosity=0),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    \n",
    "    # Distance-based Models\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    \n",
    "    # Support Vector Machine (tuned for large target values)\n",
    "    'SVR': SVR(C=1e6, epsilon=1e4, kernel='rbf'),\n",
    "}\n",
    "\n",
    "print(f\"Total models to evaluate: {len(models)}\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a329e0",
   "metadata": {},
   "source": [
    "## 5. Train and Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28777418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, tscv):\n",
    "    \"\"\"\n",
    "    Evaluate a model using time series cross-validation.\n",
    "    Returns average metrics across all folds.\n",
    "    \"\"\"\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        r2_scores.append(r2)\n",
    "    \n",
    "    return {\n",
    "        'RMSE_mean': np.mean(rmse_scores),\n",
    "        'RMSE_std': np.std(rmse_scores),\n",
    "        'MAE_mean': np.mean(mae_scores),\n",
    "        'MAE_std': np.std(mae_scores),\n",
    "        'R2_mean': np.mean(r2_scores),\n",
    "        'R2_std': np.std(r2_scores),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9816c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating models...\n",
      "============================================================\n",
      "   holiday  weathercode  temperature_2m_max  temperature_2m_min  \\\n",
      "0        1            3           -1.265259           -1.065064   \n",
      "1        0            3           -1.479549           -1.871104   \n",
      "2        0            3           -2.420040           -2.333831   \n",
      "3        0            3           -2.193846           -2.259197   \n",
      "4        0           73           -2.396230           -2.035297   \n",
      "\n",
      "   temperature_2m_mean  apparent_temperature_max  apparent_temperature_min  \\\n",
      "0            -1.162504                 -1.047366                 -0.971287   \n",
      "1            -1.685115                 -1.338638                 -2.035514   \n",
      "2            -2.395330                 -2.453509                 -2.390256   \n",
      "3            -2.247927                 -2.182324                 -2.304629   \n",
      "4            -2.261327                 -2.332983                 -2.059979   \n",
      "\n",
      "   apparent_temperature_mean   sunrise    sunset  ...  windspeed_10m_max  \\\n",
      "0                  -1.014481  1.529279 -1.425492  ...          -1.343559   \n",
      "1                  -1.735738  1.518449 -1.414899  ...           1.047793   \n",
      "2                  -2.434802  1.518449 -1.404306  ...           0.649234   \n",
      "3                  -2.246166  1.518449 -1.393713  ...           0.234733   \n",
      "4                  -2.223973  1.518449 -1.383120  ...          -0.195710   \n",
      "\n",
      "   windgusts_10m_max  shortwave_radiation_sum  et0_fao_evapotranspiration  \\\n",
      "0          -1.329472                -1.109854                   -1.213669   \n",
      "1           0.987070                -1.274036                   -1.034185   \n",
      "2           0.683898                -1.016397                   -0.922781   \n",
      "3           0.287443                -1.131324                   -0.966104   \n",
      "4          -0.155654                -1.316975                   -1.058941   \n",
      "\n",
      "   day_of_week_sin  day_of_week_cos  day_of_year_sin  day_of_year_cos  \\\n",
      "0        -0.433884        -0.900969         0.017166         0.999853   \n",
      "1        -0.974928        -0.222521         0.034328         0.999411   \n",
      "2        -0.781831         0.623490         0.051479         0.998674   \n",
      "3         0.000000         1.000000         0.068615         0.997643   \n",
      "4         0.781831         0.623490         0.085731         0.996318   \n",
      "\n",
      "   winddirection_10m_dominant_sin  winddirection_10m_dominant_cos  \n",
      "0                       -0.469472                       -0.882948  \n",
      "1                        0.992546                       -0.121869  \n",
      "2                        0.978148                       -0.207912  \n",
      "3                        0.992546                       -0.121869  \n",
      "4                        0.994522                        0.104528  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "holiday                             int64\n",
      "weathercode                         int64\n",
      "temperature_2m_max                float64\n",
      "temperature_2m_min                float64\n",
      "temperature_2m_mean               float64\n",
      "apparent_temperature_max          float64\n",
      "apparent_temperature_min          float64\n",
      "apparent_temperature_mean         float64\n",
      "sunrise                           float64\n",
      "sunset                            float64\n",
      "daylight_duration                 float64\n",
      "sunshine_duration                 float64\n",
      "rain_sum                          float64\n",
      "snowfall_sum                      float64\n",
      "precipitation_hours               float64\n",
      "windspeed_10m_max                 float64\n",
      "windgusts_10m_max                 float64\n",
      "shortwave_radiation_sum           float64\n",
      "et0_fao_evapotranspiration        float64\n",
      "day_of_week_sin                   float64\n",
      "day_of_week_cos                   float64\n",
      "day_of_year_sin                   float64\n",
      "day_of_year_cos                   float64\n",
      "winddirection_10m_dominant_sin    float64\n",
      "winddirection_10m_dominant_cos    float64\n",
      "dtype: object\n",
      "           holiday  weathercode  temperature_2m_max  temperature_2m_min  \\\n",
      "count  3560.000000  3560.000000        3.560000e+03        3.560000e+03   \n",
      "mean      0.050562    33.560955        6.386901e-17        1.596725e-17   \n",
      "std       0.219132    27.223750        1.000140e+00        1.000140e+00   \n",
      "min       0.000000     0.000000       -2.574805e+00       -3.692157e+00   \n",
      "25%       0.000000     3.000000       -8.128711e-01       -7.963838e-01   \n",
      "50%       0.000000    51.000000        2.618422e-03       -2.019712e-02   \n",
      "75%       0.000000    53.000000        8.181080e-01        8.455496e-01   \n",
      "max       1.000000    75.000000        2.520517e+00        2.368070e+00   \n",
      "\n",
      "       temperature_2m_mean  apparent_temperature_max  \\\n",
      "count         3.560000e+03              3.560000e+03   \n",
      "mean         -3.193450e-17             -6.386901e-17   \n",
      "std           1.000140e+00              1.000140e+00   \n",
      "min          -2.850940e+00             -2.574036e+00   \n",
      "25%          -8.006969e-01             -8.364440e-01   \n",
      "50%          -2.348060e-02             -4.297710e-02   \n",
      "75%           8.475376e-01              8.107531e-01   \n",
      "max           2.415370e+00              2.417775e+00   \n",
      "\n",
      "       apparent_temperature_min  apparent_temperature_mean       sunrise  \\\n",
      "count              3.560000e+03               3.560000e+03  3.560000e+03   \n",
      "mean               6.786082e-17              -3.193450e-17  1.916070e-16   \n",
      "std                1.000140e+00               1.000140e+00  1.000140e+00   \n",
      "min               -3.368855e+00              -2.601246e+00 -1.438196e+00   \n",
      "25%               -8.122648e-01              -8.258450e-01 -9.508370e-01   \n",
      "50%               -4.161795e-02              -6.020342e-02 -4.651511e-02   \n",
      "75%                8.513538e-01               8.385932e-01  9.552786e-01   \n",
      "max                2.294788e+00               2.314395e+00  1.529279e+00   \n",
      "\n",
      "             sunset  ...  windspeed_10m_max  windgusts_10m_max  \\\n",
      "count  3.560000e+03  ...       3.560000e+03       3.560000e+03   \n",
      "mean  -5.029685e-16  ...       3.193450e-17       6.786082e-17   \n",
      "std    1.000140e+00  ...       1.000140e+00       1.000140e+00   \n",
      "min   -1.531422e+00  ...      -2.156619e+00      -1.920268e+00   \n",
      "25%   -9.488077e-01  ...      -7.377499e-01      -7.153551e-01   \n",
      "50%    4.163700e-02  ...      -1.797678e-01      -1.556538e-01   \n",
      "75%    9.473377e-01  ...       6.014070e-01       5.672937e-01   \n",
      "max    1.434615e+00  ...       6.308766e+00       5.830041e+00   \n",
      "\n",
      "       shortwave_radiation_sum  et0_fao_evapotranspiration  day_of_week_sin  \\\n",
      "count             3.560000e+03                3.560000e+03      3560.000000   \n",
      "mean             -1.596725e-17               -6.386901e-17        -0.000670   \n",
      "std               1.000140e+00                1.000140e+00         0.707089   \n",
      "min              -1.405380e+00               -1.281749e+00        -0.974928   \n",
      "25%              -9.595655e-01               -9.104023e-01        -0.781831   \n",
      "50%              -1.266618e-01               -2.017493e-01         0.000000   \n",
      "75%               8.521105e-01                7.854136e-01         0.781831   \n",
      "max               2.248282e+00                3.620026e+00         0.974928   \n",
      "\n",
      "       day_of_week_cos  day_of_year_sin  day_of_year_cos  \\\n",
      "count      3560.000000      3560.000000      3560.000000   \n",
      "mean          0.000378         0.016410        -0.018343   \n",
      "std           0.707323         0.707524         0.706459   \n",
      "min          -0.900969        -0.999963        -1.000000   \n",
      "25%          -0.900969        -0.697944        -0.719121   \n",
      "50%          -0.222521         0.034328        -0.042905   \n",
      "75%           0.623490         0.722117         0.691771   \n",
      "max           1.000000         0.999963         1.000000   \n",
      "\n",
      "       winddirection_10m_dominant_sin  winddirection_10m_dominant_cos  \n",
      "count                     3560.000000                     3560.000000  \n",
      "mean                        -0.264741                       -0.121840  \n",
      "std                          0.740654                        0.605604  \n",
      "min                         -1.000000                       -1.000000  \n",
      "25%                         -0.927184                       -0.656059  \n",
      "50%                         -0.601815                       -0.173648  \n",
      "75%                          0.515038                        0.374607  \n",
      "max                          1.000000                        1.000000  \n",
      "\n",
      "[8 rows x 25 columns]\n",
      "Training: Linear Regression... Done! (RÂ² = 0.9351)\n",
      "Training: Ridge Regression... Done! (RÂ² = 0.9333)\n",
      "Training: Lasso Regression... Done! (RÂ² = 0.9314)\n",
      "Training: ElasticNet... Done! (RÂ² = 0.8929)\n",
      "Training: Decision Tree... Done! (RÂ² = 0.9092)\n",
      "Training: Random Forest... Done! (RÂ² = 0.9460)\n",
      "Training: Gradient Boosting... Done! (RÂ² = 0.9452)\n",
      "Training: AdaBoost... Done! (RÂ² = 0.9101)\n",
      "Training: XGBoost... Done! (RÂ² = 0.9392)\n",
      "Training: LightGBM... Done! (RÂ² = 0.9430)\n",
      "Training: K-Nearest Neighbors... Done! (RÂ² = 0.9123)\n",
      "Training: SVR... Done! (RÂ² = 0.9096)\n",
      "\n",
      "All models trained!\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models\n",
    "results = {}\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(X_scaled.head())\n",
    "print(X_scaled.dtypes)\n",
    "print(X_scaled.describe())\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training: {name}...\", end=\" \")\n",
    "    try:\n",
    "        metrics = evaluate_model(model, X_scaled, y, tscv)\n",
    "        results[name] = metrics\n",
    "        print(f\"Done! (RÂ² = {metrics['R2_mean']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        results[name] = {'RMSE_mean': np.nan, 'MAE_mean': np.nan, 'R2_mean': np.nan}\n",
    "\n",
    "print(\"\\nAll models trained!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5296f",
   "metadata": {},
   "source": [
    "## 6. Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('R2_mean', ascending=False)\n",
    "\n",
    "# Format for display\n",
    "results_display = results_df.copy()\n",
    "results_display['RMSE'] = results_display.apply(lambda x: f\"{x['RMSE_mean']:.2f} Â± {x['RMSE_std']:.2f}\", axis=1)\n",
    "results_display['MAE'] = results_display.apply(lambda x: f\"{x['MAE_mean']:.2f} Â± {x['MAE_std']:.2f}\", axis=1)\n",
    "results_display['RÂ²'] = results_display.apply(lambda x: f\"{x['R2_mean']:.4f} Â± {x['R2_std']:.4f}\", axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS (sorted by RÂ² score)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMetrics averaged over 10-fold Time Series Cross-Validation:\")\n",
    "print()\n",
    "results_display[['RMSE', 'MAE', 'RÂ²']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ad956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model = results_df['R2_mean'].idxmax()\n",
    "best_r2 = results_df.loc[best_model, 'R2_mean']\n",
    "best_rmse = results_df.loc[best_model, 'RMSE_mean']\n",
    "best_mae = results_df.loc[best_model, 'MAE_mean']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(f\"   - RÂ² Score: {best_r2:.4f}\")\n",
    "print(f\"   - RMSE: {best_rmse:.2f}\")\n",
    "print(f\"   - MAE: {best_mae:.2f}\")\n",
    "\n",
    "print(f\"\\nTarget variable (slp) statistics:\")\n",
    "print(f\"   - Mean: {y.mean():.2f}\")\n",
    "print(f\"   - Std: {y.std():.2f}\")\n",
    "print(f\"   - Min: {y.min():.2f}\")\n",
    "print(f\"   - Max: {y.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison (text-based bar chart)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RÂ² SCORE COMPARISON\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "max_bar_length = 50\n",
    "max_r2 = results_df['R2_mean'].max()\n",
    "\n",
    "for model_name in results_df.index:\n",
    "    r2 = results_df.loc[model_name, 'R2_mean']\n",
    "    if r2 > 0:\n",
    "        bar_length = int((r2 / max_r2) * max_bar_length)\n",
    "        bar = 'â–ˆ' * bar_length\n",
    "    else:\n",
    "        bar_length = 0\n",
    "        bar = ''\n",
    "    print(f\"{model_name:25s} | {bar} {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031b789",
   "metadata": {},
   "source": [
    "## 7. Optimal Training Timespan Analysis\n",
    "\n",
    "This section determines the optimal amount of historical data for predicting one year ahead.\n",
    "We use the last year of data as the test set and vary the training period from 1 year to all available historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test period: last 1 year of data\n",
    "test_end_date = df_clean['date'].max()\n",
    "test_start_date = test_end_date - pd.DateOffset(years=1)\n",
    "\n",
    "# Create test set mask\n",
    "test_mask = df_clean['date'] > test_start_date\n",
    "X_test_final = X_scaled[test_mask]\n",
    "y_test_final = y[test_mask]\n",
    "\n",
    "print(f\"Test period: {test_start_date.date()} to {test_end_date.date()}\")\n",
    "print(f\"Test set size: {len(X_test_final)} samples\")\n",
    "\n",
    "# Available training data (everything before test period)\n",
    "train_available_mask = df_clean['date'] <= test_start_date\n",
    "train_start_date = df_clean[train_available_mask]['date'].min()\n",
    "train_end_date = df_clean[train_available_mask]['date'].max()\n",
    "\n",
    "print(f\"\\nAvailable training period: {train_start_date.date()} to {train_end_date.date()}\")\n",
    "total_train_years = (train_end_date - train_start_date).days / 365.25\n",
    "print(f\"Total available training data: {total_train_years:.1f} years ({train_available_mask.sum()} samples)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cccbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the top 3 models based on previous results\n",
    "top_models = {\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "# Calculate max years available for training\n",
    "max_years = int(total_train_years)\n",
    "print(f\"Testing training periods from 1 to {max_years} years\\n\")\n",
    "\n",
    "# Store results for each training period\n",
    "timespan_results = {model_name: {'years': [], 'rmse': [], 'mae': [], 'r2': []} \n",
    "                    for model_name in top_models.keys()}\n",
    "\n",
    "print(\"Evaluating models with different training timespans...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for n_years in range(1, max_years + 1):\n",
    "    # Define training period: n_years before test_start_date\n",
    "    train_period_start = test_start_date - pd.DateOffset(years=n_years)\n",
    "    \n",
    "    # Create training mask for this period\n",
    "    train_mask = (df_clean['date'] > train_period_start) & (df_clean['date'] <= test_start_date)\n",
    "    \n",
    "    X_train = X_scaled[train_mask]\n",
    "    y_train = y[train_mask]\n",
    "    \n",
    "    print(f\"\\n{n_years} year(s) of training data: {train_period_start.date()} to {test_start_date.date()} ({len(X_train)} samples)\")\n",
    "    \n",
    "    for model_name, model in top_models.items():\n",
    "        # Clone the model to avoid refitting issues\n",
    "        from sklearn.base import clone\n",
    "        model_clone = clone(model)\n",
    "        \n",
    "        # Train and predict\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        y_pred = model_clone.predict(X_test_final)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_final, y_pred))\n",
    "        mae = mean_absolute_error(y_test_final, y_pred)\n",
    "        r2 = r2_score(y_test_final, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        timespan_results[model_name]['years'].append(n_years)\n",
    "        timespan_results[model_name]['rmse'].append(rmse)\n",
    "        timespan_results[model_name]['mae'].append(mae)\n",
    "        timespan_results[model_name]['r2'].append(r2)\n",
    "        \n",
    "        print(f\"  {model_name}: RÂ² = {r2:.4f}, RMSE = {rmse:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Training timespan analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive results DataFrame\n",
    "timespan_df_list = []\n",
    "for model_name, results in timespan_results.items():\n",
    "    for i in range(len(results['years'])):\n",
    "        timespan_df_list.append({\n",
    "            'Model': model_name,\n",
    "            'Training Years': results['years'][i],\n",
    "            'RMSE': results['rmse'][i],\n",
    "            'MAE': results['mae'][i],\n",
    "            'RÂ²': results['r2'][i]\n",
    "        })\n",
    "\n",
    "timespan_df = pd.DataFrame(timespan_df_list)\n",
    "\n",
    "# Pivot table for RÂ² scores\n",
    "r2_pivot = timespan_df.pivot(index='Training Years', columns='Model', values='RÂ²')\n",
    "rmse_pivot = timespan_df.pivot(index='Training Years', columns='Model', values='RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RÂ² SCORES BY TRAINING TIMESPAN\")\n",
    "print(\"=\" * 80)\n",
    "print(r2_pivot.round(4).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RMSE BY TRAINING TIMESPAN\")\n",
    "print(\"=\" * 80)\n",
    "print(rmse_pivot.round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal training timespan for each model\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMAL TRAINING TIMESPAN ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "optimal_timespans = {}\n",
    "for model_name in top_models.keys():\n",
    "    model_data = timespan_df[timespan_df['Model'] == model_name]\n",
    "    best_idx = model_data['RÂ²'].idxmax()\n",
    "    best_row = timespan_df.loc[best_idx]\n",
    "    optimal_timespans[model_name] = {\n",
    "        'years': int(best_row['Training Years']),\n",
    "        'r2': best_row['RÂ²'],\n",
    "        'rmse': best_row['RMSE'],\n",
    "        'mae': best_row['MAE']\n",
    "    }\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Optimal training period: {optimal_timespans[model_name]['years']} year(s)\")\n",
    "    print(f\"  Best RÂ²: {optimal_timespans[model_name]['r2']:.4f}\")\n",
    "    print(f\"  RMSE: {optimal_timespans[model_name]['rmse']:.2f}\")\n",
    "    print(f\"  MAE: {optimal_timespans[model_name]['mae']:.2f}\")\n",
    "\n",
    "# Calculate average RÂ² for each training timespan across all models\n",
    "avg_r2_by_years = timespan_df.groupby('Training Years')['RÂ²'].mean()\n",
    "optimal_years_overall = avg_r2_by_years.idxmax()\n",
    "optimal_r2_overall = avg_r2_by_years.max()\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"OVERALL RECOMMENDATION (averaged across all 3 models)\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nOptimal training timespan: {optimal_years_overall} year(s)\")\n",
    "print(f\"Average RÂ² score: {optimal_r2_overall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a145add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of RÂ² scores by training timespan\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RÂ² SCORE BY TRAINING TIMESPAN (Visual)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "for model_name in top_models.keys():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    model_data = timespan_df[timespan_df['Model'] == model_name].sort_values('Training Years')\n",
    "    \n",
    "    max_r2 = model_data['RÂ²'].max()\n",
    "    for _, row in model_data.iterrows():\n",
    "        years = int(row['Training Years'])\n",
    "        r2 = row['RÂ²']\n",
    "        bar_length = int((r2 / max_r2) * 40) if r2 > 0 else 0\n",
    "        bar = 'â–ˆ' * bar_length\n",
    "        marker = ' â† BEST' if r2 == max_r2 else ''\n",
    "        print(f\"  {years:2d} year(s) | {bar} {r2:.4f}{marker}\")\n",
    "\n",
    "# Average across models\n",
    "print(f\"\\nAverage (all models):\")\n",
    "for years in sorted(avg_r2_by_years.index):\n",
    "    r2 = avg_r2_by_years[years]\n",
    "    bar_length = int((r2 / avg_r2_by_years.max()) * 40) if r2 > 0 else 0\n",
    "    bar = 'â–ˆ' * bar_length\n",
    "    marker = ' â† BEST' if years == optimal_years_overall else ''\n",
    "    print(f\"  {years:2d} year(s) | {bar} {r2:.4f}{marker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08432e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY: OPTIMAL TRAINING TIMESPAN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "Test Period: {test_start_date.date()} to {test_end_date.date()} ({len(y_test_final)} days)\n",
    "\n",
    "Results by Model:\n",
    "\"\"\")\n",
    "\n",
    "for model_name, opt in optimal_timespans.items():\n",
    "    print(f\"  â€¢ {model_name}: {opt['years']} year(s) â†’ RÂ² = {opt['r2']:.4f}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "RECOMMENDATION: Use {optimal_years_overall} year(s) of historical data for training\n",
    "                when predicting 1 year ahead.\n",
    "                \n",
    "                This achieves an average RÂ² of {optimal_r2_overall:.4f} across the\n",
    "                top 3 models (Random Forest, Gradient Boosting, LightGBM).\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8214d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data with optimal training timespan + test timespan\n",
    "# Define the optimal training period start date\n",
    "optimal_train_start = test_start_date - pd.DateOffset(years=optimal_years_overall)\n",
    "\n",
    "# Create mask for optimal training + test data\n",
    "export_mask = df_clean['date'] > optimal_train_start\n",
    "\n",
    "# Create export dataframe with scaled features\n",
    "export_df_optimal = X_scaled[export_mask].copy()\n",
    "export_df_optimal['slp'] = y[export_mask].values\n",
    "export_df_optimal['date'] = df_clean.loc[export_mask, 'date'].values\n",
    "\n",
    "# Reorder columns to put date first\n",
    "cols = ['date', 'slp'] + [col for col in export_df_optimal.columns if col not in ['date', 'slp']]\n",
    "export_df_optimal = export_df_optimal[cols]\n",
    "\n",
    "# Save to CSV\n",
    "export_path = 'dataset/data_v3_full.csv'\n",
    "export_df_optimal.to_csv(export_path, sep=';', decimal=',', index=False)\n",
    "\n",
    "print(f\"Exported data to '{export_path}'\")\n",
    "print(f\"\\nData period: {optimal_train_start.date()} to {test_end_date.date()}\")\n",
    "print(f\"  - Training period: {optimal_train_start.date()} to {test_start_date.date()} ({optimal_years_overall} years)\")\n",
    "print(f\"  - Test period: {test_start_date.date()} to {test_end_date.date()} (1 year)\")\n",
    "print(f\"\\nTotal samples: {len(export_df_optimal)}\")\n",
    "print(f\"Shape: {export_df_optimal.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
