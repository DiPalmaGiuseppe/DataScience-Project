{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0eed87",
   "metadata": {},
   "source": [
    "# Model Selection for SLP Prediction\n",
    "\n",
    "This notebook performs model selection to predict the `slp` column using various machine learning algorithms with time series cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "0b7581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05222b9e",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "253b1834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3560, 26)\n",
      "\n",
      "Columns: ['date', 'entry', 'rlm', 'slp', 'day_of_year', 'day_of_week', 'holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'winddirection_10m_dominant', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>entry</th>\n",
       "      <th>rlm</th>\n",
       "      <th>slp</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weathercode</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>...</th>\n",
       "      <th>daylight_duration</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <th>windgusts_10m_max</th>\n",
       "      <th>winddirection_10m_dominant</th>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00+00:00</td>\n",
       "      <td>4.501250e+06</td>\n",
       "      <td>2.565526e+06</td>\n",
       "      <td>1.935724e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>27973.34</td>\n",
       "      <td>17706.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>208</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02 00:00:00+00:00</td>\n",
       "      <td>5.448037e+06</td>\n",
       "      <td>3.037879e+06</td>\n",
       "      <td>2.410158e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>28047.14</td>\n",
       "      <td>2501.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.2</td>\n",
       "      <td>97</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03 00:00:00+00:00</td>\n",
       "      <td>6.472305e+06</td>\n",
       "      <td>3.462336e+06</td>\n",
       "      <td>3.009970e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>...</td>\n",
       "      <td>28127.21</td>\n",
       "      <td>21285.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>44.3</td>\n",
       "      <td>102</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:00:00+00:00</td>\n",
       "      <td>7.766598e+06</td>\n",
       "      <td>4.565146e+06</td>\n",
       "      <td>3.201452e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>28213.34</td>\n",
       "      <td>9701.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>39.2</td>\n",
       "      <td>97</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05 00:00:00+00:00</td>\n",
       "      <td>7.842385e+06</td>\n",
       "      <td>4.672447e+06</td>\n",
       "      <td>3.169938e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>28305.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>33.5</td>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date         entry           rlm           slp  \\\n",
       "0  2016-01-01 00:00:00+00:00  4.501250e+06  2.565526e+06  1.935724e+06   \n",
       "1  2016-01-02 00:00:00+00:00  5.448037e+06  3.037879e+06  2.410158e+06   \n",
       "2  2016-01-03 00:00:00+00:00  6.472305e+06  3.462336e+06  3.009970e+06   \n",
       "3  2016-01-04 00:00:00+00:00  7.766598e+06  4.565146e+06  3.201452e+06   \n",
       "4  2016-01-05 00:00:00+00:00  7.842385e+06  4.672447e+06  3.169938e+06   \n",
       "\n",
       "   day_of_year  day_of_week  holiday  weathercode temperature_2m_max  \\\n",
       "0            1            4        1            3                4.3   \n",
       "1            2            5        0            3                2.5   \n",
       "2            3            6        0            3               -5.4   \n",
       "3            4            0        0            3               -3.5   \n",
       "4            5            1        0           73               -5.2   \n",
       "\n",
       "  temperature_2m_min  ... daylight_duration sunshine_duration rain_sum  \\\n",
       "0                0.1  ...          27973.34          17706.46      0.0   \n",
       "1               -5.3  ...          28047.14           2501.06      0.0   \n",
       "2               -8.4  ...          28127.21          21285.25      0.0   \n",
       "3               -7.9  ...          28213.34            9701.3      0.0   \n",
       "4               -6.4  ...          28305.35               0.0      0.0   \n",
       "\n",
       "  snowfall_sum  precipitation_hours  windspeed_10m_max windgusts_10m_max  \\\n",
       "0          0.0                  0.0                9.0              18.4   \n",
       "1          0.0                  0.0               24.0              48.2   \n",
       "2          0.0                  0.0               21.5              44.3   \n",
       "3          0.0                  0.0               18.9              39.2   \n",
       "4         2.45                 14.0               16.2              33.5   \n",
       "\n",
       "  winddirection_10m_dominant shortwave_radiation_sum  \\\n",
       "0                        208                    2.64   \n",
       "1                         97                    1.34   \n",
       "2                        102                    3.38   \n",
       "3                         97                    2.47   \n",
       "4                         84                     1.0   \n",
       "\n",
       "  et0_fao_evapotranspiration  \n",
       "0                       0.21  \n",
       "1                        0.5  \n",
       "2                       0.68  \n",
       "3                       0.61  \n",
       "4                       0.46  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset/data_v2_full.csv', sep=';', decimal=',')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6d190b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: ['rlm', 'entry']\n",
      "Dataset shape after removing rlm and entry (if present): (3560, 24)\n",
      "\n",
      "Remaining columns: ['date', 'slp', 'day_of_year', 'day_of_week', 'holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'winddirection_10m_dominant', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration']\n"
     ]
    }
   ],
   "source": [
    "# Remove 'rlm' and/or 'entry' columns if present\n",
    "to_remove = [col for col in ['rlm', 'entry'] if col in df.columns]\n",
    "if to_remove:\n",
    "    df_clean = df.drop(columns=to_remove)\n",
    "    print(f\"Removed columns: {to_remove}\")\n",
    "else:\n",
    "    df_clean = df.copy()\n",
    "    print(\"Columns 'rlm' and 'entry' not found, dataset unchanged.\")\n",
    "\n",
    "print(f\"Dataset shape after removing rlm and entry (if present): {df_clean.shape}\")\n",
    "print(f\"\\nRemaining columns: {df_clean.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b918bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date and sort by date (important for time series)\n",
    "df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "df_clean = df_clean.sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "770274c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (3560, 22)\n",
      "Target shape: (3560,)\n",
      "\n",
      "Boolean columns (not scaled): ['holiday']\n",
      "Categorical columns (not scaled): ['weathercode']\n",
      "Cyclical columns (will be sin/cos encoded): ['day_of_week', 'day_of_year', 'winddirection_10m_dominant']\n",
      "Continuous columns (will be scaled): ['temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration']\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df_clean.drop(columns=['date', 'slp'])\n",
    "y = df_clean['slp']\n",
    "\n",
    "# Define feature types for proper preprocessing\n",
    "boolean_cols = ['holiday']\n",
    "categorical_cols = ['weathercode']  # Leave as-is for tree-based models\n",
    "cyclical_cols = ['day_of_week', 'day_of_year', 'winddirection_10m_dominant']\n",
    "\n",
    "# All other columns are continuous and should be scaled\n",
    "continuous_cols = [col for col in X.columns \n",
    "                   if col not in boolean_cols + categorical_cols + cyclical_cols]\n",
    "\n",
    "# Convert continuous columns to numeric (CSV has mixed decimal formats: some use ',' some use '.')\n",
    "for col in continuous_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nBoolean columns (not scaled): {boolean_cols}\")\n",
    "print(f\"Categorical columns (not scaled): {categorical_cols}\")\n",
    "print(f\"Cyclical columns (will be sin/cos encoded): {cyclical_cols}\")\n",
    "print(f\"Continuous columns (will be scaled): {continuous_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e5877",
   "metadata": {},
   "source": [
    "## 2. Feature Preprocessing\n",
    "\n",
    "- **Boolean features** (holiday): Left unchanged (0/1)\n",
    "- **Categorical features** (weathercode): Left unchanged (tree-based models handle them well)\n",
    "- **Cyclical features** (day_of_week, day_of_year, winddirection): Sin/cos encoding to preserve circular nature\n",
    "- **Continuous features**: StandardScaler normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "0786dd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after cyclical encoding: (3560, 25)\n",
      "\n",
      "New cyclical features added:\n",
      "  day_of_week -> day_of_week_sin, day_of_week_cos\n",
      "  day_of_year -> day_of_year_sin, day_of_year_cos\n",
      "  winddirection_10m_dominant -> winddirection_10m_dominant_sin, winddirection_10m_dominant_cos\n",
      "\n",
      "All features: ['holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration', 'day_of_week_sin', 'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos', 'winddirection_10m_dominant_sin', 'winddirection_10m_dominant_cos']\n"
     ]
    }
   ],
   "source": [
    "# Apply cyclical encoding for cyclical features\n",
    "# This preserves the circular nature of these variables (e.g., day 365 is close to day 1)\n",
    "\n",
    "def cyclical_encode(df, col, max_val):\n",
    "    \"\"\"Encode a cyclical feature using sine and cosine transformation.\"\"\"\n",
    "    df[f'{col}_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "    df[f'{col}_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "    return df\n",
    "\n",
    "# Create a copy and apply cyclical encoding\n",
    "X_encoded = X.copy()\n",
    "\n",
    "# Encode day_of_week (0-6, period=7)\n",
    "X_encoded = cyclical_encode(X_encoded, 'day_of_week', 7)\n",
    "\n",
    "# Encode day_of_year (1-366, period=366)\n",
    "X_encoded = cyclical_encode(X_encoded, 'day_of_year', 366)\n",
    "\n",
    "# Encode wind direction (0-360 degrees, period=360)\n",
    "X_encoded = cyclical_encode(X_encoded, 'winddirection_10m_dominant', 360)\n",
    "\n",
    "# Drop original cyclical columns (replaced by sin/cos versions)\n",
    "X_encoded = X_encoded.drop(columns=cyclical_cols)\n",
    "\n",
    "print(f\"Shape after cyclical encoding: {X_encoded.shape}\")\n",
    "print(f\"\\nNew cyclical features added:\")\n",
    "for col in cyclical_cols:\n",
    "    print(f\"  {col} -> {col}_sin, {col}_cos\")\n",
    "print(f\"\\nAll features: {X_encoded.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "3c361f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous feature statistics before scaling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <td>-6.70</td>\n",
       "      <td>36.10</td>\n",
       "      <td>14.928006</td>\n",
       "      <td>8.401043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <td>-17.50</td>\n",
       "      <td>23.10</td>\n",
       "      <td>7.235309</td>\n",
       "      <td>6.700360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <td>-10.20</td>\n",
       "      <td>29.10</td>\n",
       "      <td>11.075225</td>\n",
       "      <td>7.463579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <td>-13.00</td>\n",
       "      <td>36.70</td>\n",
       "      <td>12.627893</td>\n",
       "      <td>9.957706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <td>-22.80</td>\n",
       "      <td>23.50</td>\n",
       "      <td>4.740225</td>\n",
       "      <td>8.176099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_mean</th>\n",
       "      <td>-14.70</td>\n",
       "      <td>29.60</td>\n",
       "      <td>8.742556</td>\n",
       "      <td>9.013316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunrise</th>\n",
       "      <td>9960.00</td>\n",
       "      <td>26400.00</td>\n",
       "      <td>17927.696629</td>\n",
       "      <td>5540.841244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset</th>\n",
       "      <td>53760.00</td>\n",
       "      <td>70560.00</td>\n",
       "      <td>62434.162921</td>\n",
       "      <td>5664.918279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight_duration</th>\n",
       "      <td>27607.04</td>\n",
       "      <td>60523.94</td>\n",
       "      <td>44506.771744</td>\n",
       "      <td>11157.694989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunshine_duration</th>\n",
       "      <td>0.00</td>\n",
       "      <td>55333.02</td>\n",
       "      <td>27306.354107</td>\n",
       "      <td>17105.955470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_sum</th>\n",
       "      <td>0.00</td>\n",
       "      <td>39.20</td>\n",
       "      <td>1.580506</td>\n",
       "      <td>3.321599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snowfall_sum</th>\n",
       "      <td>0.00</td>\n",
       "      <td>9.66</td>\n",
       "      <td>0.062253</td>\n",
       "      <td>0.387176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation_hours</th>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>3.681742</td>\n",
       "      <td>4.824554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <td>3.90</td>\n",
       "      <td>57.00</td>\n",
       "      <td>17.427612</td>\n",
       "      <td>6.273484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windgusts_10m_max</th>\n",
       "      <td>10.80</td>\n",
       "      <td>110.50</td>\n",
       "      <td>35.502331</td>\n",
       "      <td>12.865812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <td>0.30</td>\n",
       "      <td>29.23</td>\n",
       "      <td>11.427919</td>\n",
       "      <td>7.919195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8.02</td>\n",
       "      <td>2.170975</td>\n",
       "      <td>1.615968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 min       max          mean           std\n",
       "temperature_2m_max             -6.70     36.10     14.928006      8.401043\n",
       "temperature_2m_min            -17.50     23.10      7.235309      6.700360\n",
       "temperature_2m_mean           -10.20     29.10     11.075225      7.463579\n",
       "apparent_temperature_max      -13.00     36.70     12.627893      9.957706\n",
       "apparent_temperature_min      -22.80     23.50      4.740225      8.176099\n",
       "apparent_temperature_mean     -14.70     29.60      8.742556      9.013316\n",
       "sunrise                      9960.00  26400.00  17927.696629   5540.841244\n",
       "sunset                      53760.00  70560.00  62434.162921   5664.918279\n",
       "daylight_duration           27607.04  60523.94  44506.771744  11157.694989\n",
       "sunshine_duration               0.00  55333.02  27306.354107  17105.955470\n",
       "rain_sum                        0.00     39.20      1.580506      3.321599\n",
       "snowfall_sum                    0.00      9.66      0.062253      0.387176\n",
       "precipitation_hours             0.00     24.00      3.681742      4.824554\n",
       "windspeed_10m_max               3.90     57.00     17.427612      6.273484\n",
       "windgusts_10m_max              10.80    110.50     35.502331     12.865812\n",
       "shortwave_radiation_sum         0.30     29.23     11.427919      7.919195\n",
       "et0_fao_evapotranspiration      0.10      8.02      2.170975      1.615968"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature ranges before scaling (continuous features only)\n",
    "print(\"Continuous feature statistics before scaling:\")\n",
    "X_encoded[continuous_cols].describe().T[['min', 'max', 'mean', 'std']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "bdacc195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature preprocessing summary:\n",
      "  - Boolean features (unchanged): ['holiday']\n",
      "  - Categorical features (unchanged): ['weathercode']\n",
      "  - Cyclical features (sin/cos encoded): ['day_of_week_sin, day_of_week_cos', 'day_of_year_sin, day_of_year_cos', 'winddirection_10m_dominant_sin, winddirection_10m_dominant_cos']\n",
      "  - Continuous features (standardized): 17 columns\n",
      "\n",
      "Final feature matrix shape: (3560, 25)\n",
      "\n",
      "Continuous feature statistics after scaling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <td>-2.574805</td>\n",
       "      <td>2.520517</td>\n",
       "      <td>6.386901e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <td>-3.692157</td>\n",
       "      <td>2.368070</td>\n",
       "      <td>1.596725e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <td>-2.850940</td>\n",
       "      <td>2.415370</td>\n",
       "      <td>-3.193450e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <td>-2.574036</td>\n",
       "      <td>2.417775</td>\n",
       "      <td>-6.386901e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <td>-3.368855</td>\n",
       "      <td>2.294788</td>\n",
       "      <td>6.786082e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparent_temperature_mean</th>\n",
       "      <td>-2.601246</td>\n",
       "      <td>2.314395</td>\n",
       "      <td>-3.193450e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunrise</th>\n",
       "      <td>-1.438196</td>\n",
       "      <td>1.529279</td>\n",
       "      <td>1.916070e-16</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset</th>\n",
       "      <td>-1.531422</td>\n",
       "      <td>1.434615</td>\n",
       "      <td>-5.029685e-16</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight_duration</th>\n",
       "      <td>-1.514838</td>\n",
       "      <td>1.435728</td>\n",
       "      <td>2.794269e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunshine_duration</th>\n",
       "      <td>-1.596531</td>\n",
       "      <td>1.638646</td>\n",
       "      <td>-1.437053e-16</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_sum</th>\n",
       "      <td>-0.475894</td>\n",
       "      <td>11.327311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snowfall_sum</th>\n",
       "      <td>-0.160809</td>\n",
       "      <td>24.792563</td>\n",
       "      <td>1.995907e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation_hours</th>\n",
       "      <td>-0.763233</td>\n",
       "      <td>4.212019</td>\n",
       "      <td>2.195497e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <td>-2.156619</td>\n",
       "      <td>6.308766</td>\n",
       "      <td>3.193450e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windgusts_10m_max</th>\n",
       "      <td>-1.920268</td>\n",
       "      <td>5.830041</td>\n",
       "      <td>6.786082e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <td>-1.405380</td>\n",
       "      <td>2.248282</td>\n",
       "      <td>-1.596725e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <td>-1.281749</td>\n",
       "      <td>3.620026</td>\n",
       "      <td>-6.386901e-17</td>\n",
       "      <td>1.00014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 min        max          mean      std\n",
       "temperature_2m_max         -2.574805   2.520517  6.386901e-17  1.00014\n",
       "temperature_2m_min         -3.692157   2.368070  1.596725e-17  1.00014\n",
       "temperature_2m_mean        -2.850940   2.415370 -3.193450e-17  1.00014\n",
       "apparent_temperature_max   -2.574036   2.417775 -6.386901e-17  1.00014\n",
       "apparent_temperature_min   -3.368855   2.294788  6.786082e-17  1.00014\n",
       "apparent_temperature_mean  -2.601246   2.314395 -3.193450e-17  1.00014\n",
       "sunrise                    -1.438196   1.529279  1.916070e-16  1.00014\n",
       "sunset                     -1.531422   1.434615 -5.029685e-16  1.00014\n",
       "daylight_duration          -1.514838   1.435728  2.794269e-17  1.00014\n",
       "sunshine_duration          -1.596531   1.638646 -1.437053e-16  1.00014\n",
       "rain_sum                   -0.475894  11.327311  0.000000e+00  1.00014\n",
       "snowfall_sum               -0.160809  24.792563  1.995907e-17  1.00014\n",
       "precipitation_hours        -0.763233   4.212019  2.195497e-17  1.00014\n",
       "windspeed_10m_max          -2.156619   6.308766  3.193450e-17  1.00014\n",
       "windgusts_10m_max          -1.920268   5.830041  6.786082e-17  1.00014\n",
       "shortwave_radiation_sum    -1.405380   2.248282 -1.596725e-17  1.00014\n",
       "et0_fao_evapotranspiration -1.281749   3.620026 -6.386901e-17  1.00014"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply StandardScaler ONLY to continuous features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Start with the encoded data\n",
    "X_scaled = X_encoded.copy()\n",
    "\n",
    "# Scale only continuous columns\n",
    "X_scaled[continuous_cols] = scaler.fit_transform(X_encoded[continuous_cols])\n",
    "\n",
    "print(\"Feature preprocessing summary:\")\n",
    "print(f\"  - Boolean features (unchanged): {boolean_cols}\")\n",
    "print(f\"  - Categorical features (unchanged): {categorical_cols}\")\n",
    "print(f\"  - Cyclical features (sin/cos encoded): {[f'{c}_sin, {c}_cos' for c in cyclical_cols]}\")\n",
    "print(f\"  - Continuous features (standardized): {len(continuous_cols)} columns\")\n",
    "print(f\"\\nFinal feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"\\nContinuous feature statistics after scaling:\")\n",
    "X_scaled[continuous_cols].describe().T[['min', 'max', 'mean', 'std']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "1e05e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported preprocessed data to 'dataset/data_v2_step_5.csv'\n",
      "Shape: (3560, 27)\n"
     ]
    }
   ],
   "source": [
    "# Export preprocessed data to CSV\n",
    "export_df = X_scaled.copy()\n",
    "export_df['slp'] = y.values\n",
    "export_df['date'] = df_clean['date'].values\n",
    "\n",
    "# Reorder columns to put date first\n",
    "cols = ['date', 'slp'] + [col for col in export_df.columns if col not in ['date', 'slp']]\n",
    "export_df = export_df[cols]\n",
    "\n",
    "# Save to dataset folder\n",
    "export_df.to_csv('dataset/data_v2_step_5.csv', sep=';', decimal=',', index=False)\n",
    "print(f\"Exported preprocessed data to 'dataset/data_v2_step_5.csv'\")\n",
    "print(f\"Shape: {export_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063a7cc",
   "metadata": {},
   "source": [
    "## 3. Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "91c74604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series Train/Test Split:\n",
      "============================================================\n",
      "\n",
      "Train set (past data):\n",
      "  Period: 2016-01-01 to 2024-09-30\n",
      "  Samples: 3196\n",
      "\n",
      "Test set (newest 1 year):\n",
      "  Period: 2024-10-01 to 2025-09-30\n",
      "  Samples: 364\n"
     ]
    }
   ],
   "source": [
    "# Fixed train/test split: train on past data, test on newest 1 year\n",
    "# Test set: last 1 year of data\n",
    "# Train set: all data before the test period\n",
    "\n",
    "test_end = df_clean['date'].max()\n",
    "test_start = test_end - pd.DateOffset(years=1)\n",
    "\n",
    "# Create train/test masks\n",
    "train_mask_main = df_clean['date'] <= test_start\n",
    "test_mask_main = df_clean['date'] > test_start\n",
    "\n",
    "# Get indices\n",
    "train_idx_main = df_clean[train_mask_main].index.tolist()\n",
    "test_idx_main = df_clean[test_mask_main].index.tolist()\n",
    "\n",
    "# Create train/test sets\n",
    "X_train_main = X_scaled.iloc[train_idx_main]\n",
    "X_test_main = X_scaled.iloc[test_idx_main]\n",
    "y_train_main = y.iloc[train_idx_main]\n",
    "y_test_main = y.iloc[test_idx_main]\n",
    "\n",
    "print(\"Time Series Train/Test Split:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTrain set (past data):\")\n",
    "print(f\"  Period: {df_clean.iloc[train_idx_main]['date'].min().date()} to {df_clean.iloc[train_idx_main]['date'].max().date()}\")\n",
    "print(f\"  Samples: {len(train_idx_main)}\")\n",
    "\n",
    "print(f\"\\nTest set (newest 1 year):\")\n",
    "print(f\"  Period: {df_clean.iloc[test_idx_main]['date'].min().date()} to {df_clean.iloc[test_idx_main]['date'].max().date()}\")\n",
    "print(f\"  Samples: {len(test_idx_main)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dcc0a3",
   "metadata": {},
   "source": [
    "## 4. Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "5949c065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models to evaluate: 12\n",
      "  - Linear Regression\n",
      "  - Ridge Regression\n",
      "  - Lasso Regression\n",
      "  - ElasticNet\n",
      "  - Decision Tree\n",
      "  - Random Forest\n",
      "  - Gradient Boosting\n",
      "  - AdaBoost\n",
      "  - XGBoost\n",
      "  - LightGBM\n",
      "  - K-Nearest Neighbors\n",
      "  - SVR\n"
     ]
    }
   ],
   "source": [
    "# Define different types of models with standard parameters\n",
    "models = {\n",
    "    # Linear Models\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    \n",
    "    # Tree-based Models\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_jobs=-1, verbosity=0),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    \n",
    "    # Distance-based Models\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    \n",
    "    # Support Vector Machine (tuned for large target values)\n",
    "    'SVR': SVR(C=1e6, epsilon=1e4, kernel='rbf'),\n",
    "}\n",
    "\n",
    "print(f\"Total models to evaluate: {len(models)}\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a329e0",
   "metadata": {},
   "source": [
    "## 5. Train and Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "28777418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_single_split(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate a model using a single train/test split.\n",
    "    Train on past data, test on newest data.\n",
    "    \"\"\"\n",
    "    from sklearn.base import clone\n",
    "    model_clone = clone(model)\n",
    "    \n",
    "    # Train the model\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model_clone.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "9816c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating models...\n",
      "============================================================\n",
      "Train: 3196 samples | Test: 364 samples (newest 1 year)\n",
      "============================================================\n",
      "Training: Linear Regression... Done! (R² = 0.9529)\n",
      "Training: Ridge Regression... Done! (R² = 0.9541)\n",
      "Training: Lasso Regression... Done! (R² = 0.9516)\n",
      "Training: ElasticNet... Done! (R² = 0.9179)\n",
      "Training: Decision Tree... Done! (R² = 0.8393)\n",
      "Training: Random Forest... Done! (R² = 0.9658)\n",
      "Training: Gradient Boosting... Done! (R² = 0.9726)\n",
      "Training: AdaBoost... Done! (R² = 0.9365)\n",
      "Training: XGBoost... Done! (R² = 0.9532)\n",
      "Training: LightGBM... Done! (R² = 0.9686)\n",
      "Training: K-Nearest Neighbors... Done! (R² = 0.9492)\n",
      "Training: SVR... Done! (R² = 0.9466)\n",
      "\n",
      "All models trained!\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models using single train/test split\n",
    "results = {}\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train: {len(X_train_main)} samples | Test: {len(X_test_main)} samples (newest 1 year)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training: {name}...\", end=\" \")\n",
    "    try:\n",
    "        metrics = evaluate_model_single_split(model, X_train_main, X_test_main, y_train_main, y_test_main)\n",
    "        results[name] = metrics\n",
    "        print(f\"Done! (R² = {metrics['R2']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        results[name] = {'RMSE': np.nan, 'MAE': np.nan, 'R2': np.nan}\n",
    "\n",
    "print(\"\\nAll models trained!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5296f",
   "metadata": {},
   "source": [
    "## 6. Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "aea8d55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON RESULTS (sorted by R² score)\n",
      "================================================================================\n",
      "\n",
      "Train/Test Split: Train on past data, Test on newest 1 year\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>113948.63</td>\n",
       "      <td>84081.41</td>\n",
       "      <td>0.9726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>122178.16</td>\n",
       "      <td>86431.19</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>127367.30</td>\n",
       "      <td>87380.37</td>\n",
       "      <td>0.9658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>147543.92</td>\n",
       "      <td>118234.78</td>\n",
       "      <td>0.9541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>149041.34</td>\n",
       "      <td>97857.87</td>\n",
       "      <td>0.9532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>149468.96</td>\n",
       "      <td>118886.27</td>\n",
       "      <td>0.9529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression</th>\n",
       "      <td>151636.33</td>\n",
       "      <td>122385.10</td>\n",
       "      <td>0.9516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>155227.98</td>\n",
       "      <td>112004.32</td>\n",
       "      <td>0.9492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>159204.14</td>\n",
       "      <td>128672.90</td>\n",
       "      <td>0.9466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>173621.09</td>\n",
       "      <td>142553.20</td>\n",
       "      <td>0.9365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>197406.28</td>\n",
       "      <td>160699.32</td>\n",
       "      <td>0.9179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>276187.73</td>\n",
       "      <td>148114.90</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          RMSE        MAE      R²\n",
       "Gradient Boosting    113948.63   84081.41  0.9726\n",
       "LightGBM             122178.16   86431.19  0.9686\n",
       "Random Forest        127367.30   87380.37  0.9658\n",
       "Ridge Regression     147543.92  118234.78  0.9541\n",
       "XGBoost              149041.34   97857.87  0.9532\n",
       "Linear Regression    149468.96  118886.27  0.9529\n",
       "Lasso Regression     151636.33  122385.10  0.9516\n",
       "K-Nearest Neighbors  155227.98  112004.32  0.9492\n",
       "SVR                  159204.14  128672.90  0.9466\n",
       "AdaBoost             173621.09  142553.20  0.9365\n",
       "ElasticNet           197406.28  160699.32  0.9179\n",
       "Decision Tree        276187.73  148114.90  0.8393"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('R2', ascending=False)\n",
    "\n",
    "# Format for display\n",
    "results_display = results_df.copy()\n",
    "results_display['RMSE_fmt'] = results_display['RMSE'].apply(lambda x: f\"{x:.2f}\")\n",
    "results_display['MAE_fmt'] = results_display['MAE'].apply(lambda x: f\"{x:.2f}\")\n",
    "results_display['R²_fmt'] = results_display['R2'].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON RESULTS (sorted by R² score)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTrain/Test Split: Train on past data, Test on newest 1 year\")\n",
    "print()\n",
    "results_display[['RMSE_fmt', 'MAE_fmt', 'R²_fmt']].rename(columns={'RMSE_fmt': 'RMSE', 'MAE_fmt': 'MAE', 'R²_fmt': 'R²'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "5a1ad956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Best Model: Gradient Boosting\n",
      "   - R² Score: 0.9726\n",
      "   - RMSE: 113948.63\n",
      "   - MAE: 84081.41\n",
      "\n",
      "Target variable (slp) statistics:\n",
      "   - Mean: 988192.36\n",
      "   - Std: 752107.47\n",
      "   - Min: -435171.56\n",
      "   - Max: 3341410.76\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_model = results_df['R2'].idxmax()\n",
    "best_r2 = results_df.loc[best_model, 'R2']\n",
    "best_rmse = results_df.loc[best_model, 'RMSE']\n",
    "best_mae = results_df.loc[best_model, 'MAE']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(f\"   - R² Score: {best_r2:.4f}\")\n",
    "print(f\"   - RMSE: {best_rmse:.2f}\")\n",
    "print(f\"   - MAE: {best_mae:.2f}\")\n",
    "\n",
    "print(f\"\\nTarget variable (slp) statistics:\")\n",
    "print(f\"   - Mean: {y.mean():.2f}\")\n",
    "print(f\"   - Std: {y.std():.2f}\")\n",
    "print(f\"   - Min: {y.min():.2f}\")\n",
    "print(f\"   - Max: {y.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "3c02fc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "R² SCORE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Gradient Boosting         | ██████████████████████████████████████████████████ 0.9726\n",
      "LightGBM                  | █████████████████████████████████████████████████ 0.9686\n",
      "Random Forest             | █████████████████████████████████████████████████ 0.9658\n",
      "Ridge Regression          | █████████████████████████████████████████████████ 0.9541\n",
      "XGBoost                   | █████████████████████████████████████████████████ 0.9532\n",
      "Linear Regression         | ████████████████████████████████████████████████ 0.9529\n",
      "Lasso Regression          | ████████████████████████████████████████████████ 0.9516\n",
      "K-Nearest Neighbors       | ████████████████████████████████████████████████ 0.9492\n",
      "SVR                       | ████████████████████████████████████████████████ 0.9466\n",
      "AdaBoost                  | ████████████████████████████████████████████████ 0.9365\n",
      "ElasticNet                | ███████████████████████████████████████████████ 0.9179\n",
      "Decision Tree             | ███████████████████████████████████████████ 0.8393\n"
     ]
    }
   ],
   "source": [
    "# Visual comparison (text-based bar chart)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"R² SCORE COMPARISON\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "max_bar_length = 50\n",
    "max_r2 = results_df['R2'].max()\n",
    "\n",
    "for model_name in results_df.index:\n",
    "    r2 = results_df.loc[model_name, 'R2']\n",
    "    if r2 > 0:\n",
    "        bar_length = int((r2 / max_r2) * max_bar_length)\n",
    "        bar = '█' * bar_length\n",
    "    else:\n",
    "        bar_length = 0\n",
    "        bar = ''\n",
    "    print(f\"{model_name:25s} | {bar} {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031b789",
   "metadata": {},
   "source": [
    "## 7. Optimal Training Timespan Analysis\n",
    "\n",
    "This section determines the optimal amount of historical data for predicting one year ahead.\n",
    "We use the last year of data as the test set and vary the training period from 1 year to all available historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "af45d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period: 2024-09-30 to 2025-09-30\n",
      "Test set size: 364 samples\n",
      "\n",
      "Available training period: 2016-01-01 to 2024-09-30\n",
      "Total available training data: 8.7 years (3196 samples)\n"
     ]
    }
   ],
   "source": [
    "# Define the test period: last 1 year of data\n",
    "test_end_date = df_clean['date'].max()\n",
    "test_start_date = test_end_date - pd.DateOffset(years=1)\n",
    "\n",
    "# Create test set mask\n",
    "test_mask = df_clean['date'] > test_start_date\n",
    "X_test_final = X_scaled[test_mask]\n",
    "y_test_final = y[test_mask]\n",
    "\n",
    "print(f\"Test period: {test_start_date.date()} to {test_end_date.date()}\")\n",
    "print(f\"Test set size: {len(X_test_final)} samples\")\n",
    "\n",
    "# Available training data (everything before test period)\n",
    "train_available_mask = df_clean['date'] <= test_start_date\n",
    "train_start_date = df_clean[train_available_mask]['date'].min()\n",
    "train_end_date = df_clean[train_available_mask]['date'].max()\n",
    "\n",
    "print(f\"\\nAvailable training period: {train_start_date.date()} to {train_end_date.date()}\")\n",
    "total_train_years = (train_end_date - train_start_date).days / 365.25\n",
    "print(f\"Total available training data: {total_train_years:.1f} years ({train_available_mask.sum()} samples)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e4cccbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing training periods from 1 to 8 years\n",
      "\n",
      "Evaluating models with different training timespans...\n",
      "======================================================================\n",
      "\n",
      "1 year(s) of training data: 2023-09-30 to 2024-09-30 (366 samples)\n",
      "  Gradient Boosting: R² = 0.9528, RMSE = 149755.45\n",
      "  LightGBM: R² = 0.9498, RMSE = 154429.61\n",
      "  Random Forest: R² = 0.9642, RMSE = 130379.30\n",
      "\n",
      "2 year(s) of training data: 2022-09-30 to 2024-09-30 (731 samples)\n",
      "  Gradient Boosting: R² = 0.9741, RMSE = 110844.72\n",
      "  LightGBM: R² = 0.9754, RMSE = 108016.84\n",
      "  Random Forest: R² = 0.9746, RMSE = 109777.40\n",
      "\n",
      "3 year(s) of training data: 2021-09-30 to 2024-09-30 (1096 samples)\n",
      "  Gradient Boosting: R² = 0.9766, RMSE = 105484.76\n",
      "  LightGBM: R² = 0.9738, RMSE = 111470.16\n",
      "  Random Forest: R² = 0.9745, RMSE = 110079.05\n",
      "\n",
      "4 year(s) of training data: 2020-09-30 to 2024-09-30 (1461 samples)\n",
      "  Gradient Boosting: R² = 0.9746, RMSE = 109892.19\n",
      "  LightGBM: R² = 0.9700, RMSE = 119244.25\n",
      "  Random Forest: R² = 0.9677, RMSE = 123747.13\n",
      "\n",
      "5 year(s) of training data: 2019-09-30 to 2024-09-30 (1827 samples)\n",
      "  Gradient Boosting: R² = 0.9691, RMSE = 121149.41\n",
      "  LightGBM: R² = 0.9603, RMSE = 137244.59\n",
      "  Random Forest: R² = 0.9566, RMSE = 143454.94\n",
      "\n",
      "6 year(s) of training data: 2018-09-30 to 2024-09-30 (2192 samples)\n",
      "  Gradient Boosting: R² = 0.9723, RMSE = 114611.99\n",
      "  LightGBM: R² = 0.9653, RMSE = 128329.46\n",
      "  Random Forest: R² = 0.9641, RMSE = 130514.49\n",
      "\n",
      "7 year(s) of training data: 2017-09-30 to 2024-09-30 (2557 samples)\n",
      "  Gradient Boosting: R² = 0.9732, RMSE = 112853.42\n",
      "  LightGBM: R² = 0.9652, RMSE = 128489.57\n",
      "  Random Forest: R² = 0.9690, RMSE = 121279.48\n",
      "\n",
      "8 year(s) of training data: 2016-09-30 to 2024-09-30 (2922 samples)\n",
      "  Gradient Boosting: R² = 0.9724, RMSE = 114376.18\n",
      "  LightGBM: R² = 0.9639, RMSE = 130880.13\n",
      "  Random Forest: R² = 0.9660, RMSE = 127014.43\n",
      "\n",
      "======================================================================\n",
      "Training timespan analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Define the top 3 models based on previous results\n",
    "top_models = {\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "# Calculate max years available for training\n",
    "max_years = int(total_train_years)\n",
    "print(f\"Testing training periods from 1 to {max_years} years\\n\")\n",
    "\n",
    "# Store results for each training period\n",
    "timespan_results = {model_name: {'years': [], 'rmse': [], 'mae': [], 'r2': []} \n",
    "                    for model_name in top_models.keys()}\n",
    "\n",
    "print(\"Evaluating models with different training timespans...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for n_years in range(1, max_years + 1):\n",
    "    # Define training period: n_years before test_start_date\n",
    "    train_period_start = test_start_date - pd.DateOffset(years=n_years)\n",
    "    \n",
    "    # Create training mask for this period\n",
    "    train_mask = (df_clean['date'] > train_period_start) & (df_clean['date'] <= test_start_date)\n",
    "    \n",
    "    X_train = X_scaled[train_mask]\n",
    "    y_train = y[train_mask]\n",
    "    \n",
    "    print(f\"\\n{n_years} year(s) of training data: {train_period_start.date()} to {test_start_date.date()} ({len(X_train)} samples)\")\n",
    "    \n",
    "    for model_name, model in top_models.items():\n",
    "        # Clone the model to avoid refitting issues\n",
    "        from sklearn.base import clone\n",
    "        model_clone = clone(model)\n",
    "        \n",
    "        # Train and predict\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        y_pred = model_clone.predict(X_test_final)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_final, y_pred))\n",
    "        mae = mean_absolute_error(y_test_final, y_pred)\n",
    "        r2 = r2_score(y_test_final, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        timespan_results[model_name]['years'].append(n_years)\n",
    "        timespan_results[model_name]['rmse'].append(rmse)\n",
    "        timespan_results[model_name]['mae'].append(mae)\n",
    "        timespan_results[model_name]['r2'].append(r2)\n",
    "        \n",
    "        print(f\"  {model_name}: R² = {r2:.4f}, RMSE = {rmse:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Training timespan analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f843b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "R² SCORES BY TRAINING TIMESPAN\n",
      "================================================================================\n",
      "Model           Gradient Boosting  LightGBM  Random Forest\n",
      "Training Years                                            \n",
      "1                          0.9528    0.9498         0.9642\n",
      "2                          0.9741    0.9754         0.9746\n",
      "3                          0.9766    0.9738         0.9745\n",
      "4                          0.9746    0.9700         0.9677\n",
      "5                          0.9691    0.9603         0.9566\n",
      "6                          0.9723    0.9653         0.9641\n",
      "7                          0.9732    0.9652         0.9690\n",
      "8                          0.9724    0.9639         0.9660\n",
      "\n",
      "================================================================================\n",
      "RMSE BY TRAINING TIMESPAN\n",
      "================================================================================\n",
      "Model           Gradient Boosting   LightGBM  Random Forest\n",
      "Training Years                                             \n",
      "1                       149755.45  154429.61      130379.30\n",
      "2                       110844.72  108016.84      109777.40\n",
      "3                       105484.76  111470.16      110079.05\n",
      "4                       109892.19  119244.25      123747.13\n",
      "5                       121149.41  137244.59      143454.94\n",
      "6                       114611.99  128329.46      130514.49\n",
      "7                       112853.42  128489.57      121279.48\n",
      "8                       114376.18  130880.13      127014.43\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive results DataFrame\n",
    "timespan_df_list = []\n",
    "for model_name, results in timespan_results.items():\n",
    "    for i in range(len(results['years'])):\n",
    "        timespan_df_list.append({\n",
    "            'Model': model_name,\n",
    "            'Training Years': results['years'][i],\n",
    "            'RMSE': results['rmse'][i],\n",
    "            'MAE': results['mae'][i],\n",
    "            'R²': results['r2'][i]\n",
    "        })\n",
    "\n",
    "timespan_df = pd.DataFrame(timespan_df_list)\n",
    "\n",
    "# Pivot table for R² scores\n",
    "r2_pivot = timespan_df.pivot(index='Training Years', columns='Model', values='R²')\n",
    "rmse_pivot = timespan_df.pivot(index='Training Years', columns='Model', values='RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"R² SCORES BY TRAINING TIMESPAN\")\n",
    "print(\"=\" * 80)\n",
    "print(r2_pivot.round(4).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RMSE BY TRAINING TIMESPAN\")\n",
    "print(\"=\" * 80)\n",
    "print(rmse_pivot.round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "9aea379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMAL TRAINING TIMESPAN ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Gradient Boosting:\n",
      "  Optimal training period: 3 year(s)\n",
      "  Best R²: 0.9766\n",
      "  RMSE: 105484.76\n",
      "  MAE: 71462.74\n",
      "\n",
      "LightGBM:\n",
      "  Optimal training period: 2 year(s)\n",
      "  Best R²: 0.9754\n",
      "  RMSE: 108016.84\n",
      "  MAE: 72961.57\n",
      "\n",
      "Random Forest:\n",
      "  Optimal training period: 2 year(s)\n",
      "  Best R²: 0.9746\n",
      "  RMSE: 109777.40\n",
      "  MAE: 73192.08\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "OVERALL RECOMMENDATION (averaged across all 3 models)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Optimal training timespan: 3 year(s)\n",
      "Average R² score: 0.9749\n"
     ]
    }
   ],
   "source": [
    "# Find optimal training timespan for each model\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMAL TRAINING TIMESPAN ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "optimal_timespans = {}\n",
    "for model_name in top_models.keys():\n",
    "    model_data = timespan_df[timespan_df['Model'] == model_name]\n",
    "    best_idx = model_data['R²'].idxmax()\n",
    "    best_row = timespan_df.loc[best_idx]\n",
    "    optimal_timespans[model_name] = {\n",
    "        'years': int(best_row['Training Years']),\n",
    "        'r2': best_row['R²'],\n",
    "        'rmse': best_row['RMSE'],\n",
    "        'mae': best_row['MAE']\n",
    "    }\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Optimal training period: {optimal_timespans[model_name]['years']} year(s)\")\n",
    "    print(f\"  Best R²: {optimal_timespans[model_name]['r2']:.4f}\")\n",
    "    print(f\"  RMSE: {optimal_timespans[model_name]['rmse']:.2f}\")\n",
    "    print(f\"  MAE: {optimal_timespans[model_name]['mae']:.2f}\")\n",
    "\n",
    "# Calculate average R² for each training timespan across all models\n",
    "avg_r2_by_years = timespan_df.groupby('Training Years')['R²'].mean()\n",
    "optimal_years_overall = avg_r2_by_years.idxmax()\n",
    "optimal_r2_overall = avg_r2_by_years.max()\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"OVERALL RECOMMENDATION (averaged across all 3 models)\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nOptimal training timespan: {optimal_years_overall} year(s)\")\n",
    "print(f\"Average R² score: {optimal_r2_overall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6a145add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "R² SCORE BY TRAINING TIMESPAN (Visual)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "   1 year(s) | ███████████████████████████████████████ 0.9528\n",
      "   2 year(s) | ███████████████████████████████████████ 0.9741\n",
      "   3 year(s) | ████████████████████████████████████████ 0.9766 ← BEST\n",
      "   4 year(s) | ███████████████████████████████████████ 0.9746\n",
      "   5 year(s) | ███████████████████████████████████████ 0.9691\n",
      "   6 year(s) | ███████████████████████████████████████ 0.9723\n",
      "   7 year(s) | ███████████████████████████████████████ 0.9732\n",
      "   8 year(s) | ███████████████████████████████████████ 0.9724\n",
      "\n",
      "LightGBM:\n",
      "   1 year(s) | ██████████████████████████████████████ 0.9498\n",
      "   2 year(s) | ████████████████████████████████████████ 0.9754 ← BEST\n",
      "   3 year(s) | ███████████████████████████████████████ 0.9738\n",
      "   4 year(s) | ███████████████████████████████████████ 0.9700\n",
      "   5 year(s) | ███████████████████████████████████████ 0.9603\n",
      "   6 year(s) | ███████████████████████████████████████ 0.9653\n",
      "   7 year(s) | ███████████████████████████████████████ 0.9652\n",
      "   8 year(s) | ███████████████████████████████████████ 0.9639\n",
      "\n",
      "Random Forest:\n",
      "   1 year(s) | ███████████████████████████████████████ 0.9642\n",
      "   2 year(s) | ████████████████████████████████████████ 0.9746 ← BEST\n",
      "   3 year(s) | ███████████████████████████████████████ 0.9745\n",
      "   4 year(s) | ███████████████████████████████████████ 0.9677\n",
      "   5 year(s) | ███████████████████████████████████████ 0.9566\n",
      "   6 year(s) | ███████████████████████████████████████ 0.9641\n",
      "   7 year(s) | ███████████████████████████████████████ 0.9690\n",
      "   8 year(s) | ███████████████████████████████████████ 0.9660\n",
      "\n",
      "Average (all models):\n",
      "   1 year(s) | ███████████████████████████████████████ 0.9556\n",
      "   2 year(s) | ███████████████████████████████████████ 0.9747\n",
      "   3 year(s) | ████████████████████████████████████████ 0.9749 ← BEST\n",
      "   4 year(s) | ███████████████████████████████████████ 0.9708\n",
      "   5 year(s) | ███████████████████████████████████████ 0.9620\n",
      "   6 year(s) | ███████████████████████████████████████ 0.9672\n",
      "   7 year(s) | ███████████████████████████████████████ 0.9691\n",
      "   8 year(s) | ███████████████████████████████████████ 0.9675\n"
     ]
    }
   ],
   "source": [
    "# Visual comparison of R² scores by training timespan\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"R² SCORE BY TRAINING TIMESPAN (Visual)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "for model_name in top_models.keys():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    model_data = timespan_df[timespan_df['Model'] == model_name].sort_values('Training Years')\n",
    "    \n",
    "    max_r2 = model_data['R²'].max()\n",
    "    for _, row in model_data.iterrows():\n",
    "        years = int(row['Training Years'])\n",
    "        r2 = row['R²']\n",
    "        bar_length = int((r2 / max_r2) * 40) if r2 > 0 else 0\n",
    "        bar = '█' * bar_length\n",
    "        marker = ' ← BEST' if r2 == max_r2 else ''\n",
    "        print(f\"  {years:2d} year(s) | {bar} {r2:.4f}{marker}\")\n",
    "\n",
    "# Average across models\n",
    "print(f\"\\nAverage (all models):\")\n",
    "for years in sorted(avg_r2_by_years.index):\n",
    "    r2 = avg_r2_by_years[years]\n",
    "    bar_length = int((r2 / avg_r2_by_years.max()) * 40) if r2 > 0 else 0\n",
    "    bar = '█' * bar_length\n",
    "    marker = ' ← BEST' if years == optimal_years_overall else ''\n",
    "    print(f\"  {years:2d} year(s) | {bar} {r2:.4f}{marker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "08432e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY: OPTIMAL TRAINING TIMESPAN\n",
      "================================================================================\n",
      "\n",
      "Test Period: 2024-09-30 to 2025-09-30 (364 days)\n",
      "\n",
      "Results by Model:\n",
      "\n",
      "  • Gradient Boosting: 3 year(s) → R² = 0.9766\n",
      "  • LightGBM: 2 year(s) → R² = 0.9754\n",
      "  • Random Forest: 2 year(s) → R² = 0.9746\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "RECOMMENDATION: Use 3 year(s) of historical data for training\n",
      "                when predicting 1 year ahead.\n",
      "                \n",
      "                This achieves an average R² of 0.9749 across the\n",
      "                top 3 models (Random Forest, Gradient Boosting, LightGBM).\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY: OPTIMAL TRAINING TIMESPAN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "Test Period: {test_start_date.date()} to {test_end_date.date()} ({len(y_test_final)} days)\n",
    "\n",
    "Results by Model:\n",
    "\"\"\")\n",
    "\n",
    "for model_name, opt in optimal_timespans.items():\n",
    "    print(f\"  • {model_name}: {opt['years']} year(s) → R² = {opt['r2']:.4f}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "════════════════════════════════════════════════════════════════════════════════\n",
    "RECOMMENDATION: Use {optimal_years_overall} year(s) of historical data for training\n",
    "                when predicting 1 year ahead.\n",
    "                \n",
    "                This achieves an average R² of {optimal_r2_overall:.4f} across the\n",
    "                top 3 models (Random Forest, Gradient Boosting, LightGBM).\n",
    "════════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "7d8214d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported data to 'dataset/data_v2_step_5_and_4.csv'\n",
      "\n",
      "Data period: 2021-09-30 to 2025-09-30\n",
      "  - Training period: 2021-09-30 to 2024-09-30 (3 years)\n",
      "  - Test period: 2024-09-30 to 2025-09-30 (1 year)\n",
      "\n",
      "Total samples: 1460\n",
      "Shape: (1460, 27)\n"
     ]
    }
   ],
   "source": [
    "# Export data with optimal training timespan + test timespan\n",
    "# Define the optimal training period start date\n",
    "optimal_train_start = test_start_date - pd.DateOffset(years=optimal_years_overall)\n",
    "\n",
    "# Create mask for optimal training + test data\n",
    "export_mask = df_clean['date'] > optimal_train_start\n",
    "\n",
    "# Create export dataframe with scaled features\n",
    "export_df_optimal = X_scaled[export_mask].copy()\n",
    "export_df_optimal['slp'] = y[export_mask].values\n",
    "export_df_optimal['date'] = df_clean.loc[export_mask, 'date'].values\n",
    "\n",
    "# Reorder columns to put date first\n",
    "cols = ['date', 'slp'] + [col for col in export_df_optimal.columns if col not in ['date', 'slp']]\n",
    "export_df_optimal = export_df_optimal[cols]\n",
    "\n",
    "# Save to CSV\n",
    "export_path = 'dataset/data_v2_step_5_and_4.csv'\n",
    "export_df_optimal.to_csv(export_path, sep=';', decimal=',', index=False)\n",
    "\n",
    "print(f\"Exported data to '{export_path}'\")\n",
    "print(f\"\\nData period: {optimal_train_start.date()} to {test_end_date.date()}\")\n",
    "print(f\"  - Training period: {optimal_train_start.date()} to {test_start_date.date()} ({optimal_years_overall} years)\")\n",
    "print(f\"  - Test period: {test_start_date.date()} to {test_end_date.date()} (1 year)\")\n",
    "print(f\"\\nTotal samples: {len(export_df_optimal)}\")\n",
    "print(f\"Shape: {export_df_optimal.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f668a36b",
   "metadata": {},
   "source": [
    "## 8. Model Selection on Optimal Timespan Dataset\n",
    "\n",
    "Now we repeat the model selection process (Steps 4-6) using only the optimal training timespan + test data exported to `data_v2_step_5_and_4.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "9cec978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal timespan dataset shape: (1460, 27)\n",
      "\n",
      "Columns: ['date', 'slp', 'holiday', 'weathercode', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean', 'sunrise', 'sunset', 'daylight_duration', 'sunshine_duration', 'rain_sum', 'snowfall_sum', 'precipitation_hours', 'windspeed_10m_max', 'windgusts_10m_max', 'shortwave_radiation_sum', 'et0_fao_evapotranspiration', 'day_of_week_sin', 'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos', 'winddirection_10m_dominant_sin', 'winddirection_10m_dominant_cos']\n",
      "\n",
      "Features shape: (1460, 25)\n",
      "Target shape: (1460,)\n",
      "\n",
      "Date range: 2021-10-01 to 2025-09-30\n"
     ]
    }
   ],
   "source": [
    "# Load the optimal timespan dataset\n",
    "df_optimal = pd.read_csv('dataset/data_v2_step_5_and_4.csv', sep=';', decimal=',')\n",
    "\n",
    "print(f\"Optimal timespan dataset shape: {df_optimal.shape}\")\n",
    "print(f\"\\nColumns: {df_optimal.columns.tolist()}\")\n",
    "\n",
    "# Parse date and sort\n",
    "df_optimal['date'] = pd.to_datetime(df_optimal['date'])\n",
    "df_optimal = df_optimal.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Separate features and target\n",
    "X_opt = df_optimal.drop(columns=['date', 'slp'])\n",
    "y_opt = df_optimal['slp']\n",
    "\n",
    "print(f\"\\nFeatures shape: {X_opt.shape}\")\n",
    "print(f\"Target shape: {y_opt.shape}\")\n",
    "print(f\"\\nDate range: {df_optimal['date'].min().date()} to {df_optimal['date'].max().date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "d05a62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series Train/Test Split (Optimal Dataset):\n",
      "============================================================\n",
      "\n",
      "Train set (past data):\n",
      "  Period: 2021-10-01 to 2024-09-30\n",
      "  Samples: 1096\n",
      "\n",
      "Test set (newest 1 year):\n",
      "  Period: 2024-10-01 to 2025-09-30\n",
      "  Samples: 364\n"
     ]
    }
   ],
   "source": [
    "# Fixed train/test split for optimal dataset: train on past data, test on newest 1 year\n",
    "test_end_opt = df_optimal['date'].max()\n",
    "test_start_opt = test_end_opt - pd.DateOffset(years=1)\n",
    "\n",
    "# Create train/test masks\n",
    "train_mask_opt = df_optimal['date'] <= test_start_opt\n",
    "test_mask_opt = df_optimal['date'] > test_start_opt\n",
    "\n",
    "# Get indices\n",
    "train_idx_opt = df_optimal[train_mask_opt].index.tolist()\n",
    "test_idx_opt = df_optimal[test_mask_opt].index.tolist()\n",
    "\n",
    "# Create train/test sets\n",
    "X_train_opt = X_opt.iloc[train_idx_opt]\n",
    "X_test_opt = X_opt.iloc[test_idx_opt]\n",
    "y_train_opt = y_opt.iloc[train_idx_opt]\n",
    "y_test_opt = y_opt.iloc[test_idx_opt]\n",
    "\n",
    "print(\"Time Series Train/Test Split (Optimal Dataset):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTrain set (past data):\")\n",
    "print(f\"  Period: {df_optimal.iloc[train_idx_opt]['date'].min().date()} to {df_optimal.iloc[train_idx_opt]['date'].max().date()}\")\n",
    "print(f\"  Samples: {len(train_idx_opt)}\")\n",
    "\n",
    "print(f\"\\nTest set (newest 1 year):\")\n",
    "print(f\"  Period: {df_optimal.iloc[test_idx_opt]['date'].min().date()} to {df_optimal.iloc[test_idx_opt]['date'].max().date()}\")\n",
    "print(f\"  Samples: {len(test_idx_opt)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f304b9d",
   "metadata": {},
   "source": [
    "### 8.1 Define Models (on Optimal Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "36fb6ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models to evaluate: 12\n",
      "  - Linear Regression\n",
      "  - Ridge Regression\n",
      "  - Lasso Regression\n",
      "  - ElasticNet\n",
      "  - Decision Tree\n",
      "  - Random Forest\n",
      "  - Gradient Boosting\n",
      "  - AdaBoost\n",
      "  - XGBoost\n",
      "  - LightGBM\n",
      "  - K-Nearest Neighbors\n",
      "  - SVR\n"
     ]
    }
   ],
   "source": [
    "# Define the same models for comparison on optimal dataset\n",
    "models_opt = {\n",
    "    # Linear Models\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    \n",
    "    # Tree-based Models\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_jobs=-1, verbosity=0),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    \n",
    "    # Distance-based Models\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    \n",
    "    # Support Vector Machine\n",
    "    'SVR': SVR(C=1e6, epsilon=1e4, kernel='rbf'),\n",
    "}\n",
    "\n",
    "print(f\"Total models to evaluate: {len(models_opt)}\")\n",
    "for name in models_opt.keys():\n",
    "    print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c673e",
   "metadata": {},
   "source": [
    "### 8.2 Train and Test Models (on Optimal Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "f2f8a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating models on optimal timespan dataset...\n",
      "============================================================\n",
      "Train: 1096 samples | Test: 364 samples (newest 1 year)\n",
      "============================================================\n",
      "Training: Linear Regression... Done! (R² = 0.9717)\n",
      "Training: Ridge Regression... Done! (R² = 0.9731)\n",
      "Training: Lasso Regression... Done! (R² = 0.9699)\n",
      "Training: ElasticNet... Done! (R² = 0.9320)\n",
      "Training: Decision Tree... Done! (R² = 0.9448)\n",
      "Training: Random Forest... Done! (R² = 0.9745)\n",
      "Training: Gradient Boosting... Done! (R² = 0.9766)\n",
      "Training: AdaBoost... Done! (R² = 0.9397)\n",
      "Training: XGBoost... Done! (R² = 0.9715)\n",
      "Training: LightGBM... Done! (R² = 0.9741)\n",
      "Training: K-Nearest Neighbors... Done! (R² = 0.9546)\n",
      "Training: SVR... Done! (R² = 0.9497)\n",
      "\n",
      "All models trained!\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models on optimal dataset using single train/test split\n",
    "results_opt = {}\n",
    "\n",
    "print(\"Training and evaluating models on optimal timespan dataset...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train: {len(X_train_opt)} samples | Test: {len(X_test_opt)} samples (newest 1 year)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models_opt.items():\n",
    "    print(f\"Training: {name}...\", end=\" \")\n",
    "    try:\n",
    "        metrics = evaluate_model_single_split(model, X_train_opt, X_test_opt, y_train_opt, y_test_opt)\n",
    "        results_opt[name] = metrics\n",
    "        print(f\"Done! (R² = {metrics['R2']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        results_opt[name] = {'RMSE': np.nan, 'MAE': np.nan, 'R2': np.nan}\n",
    "\n",
    "print(\"\\nAll models trained!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415fe06",
   "metadata": {},
   "source": [
    "### 8.3 Results (on Optimal Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "79e595f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON RESULTS - OPTIMAL TIMESPAN DATASET (sorted by R² score)\n",
      "================================================================================\n",
      "\n",
      "Dataset: 1460 samples (3 years training + 1 year test)\n",
      "Train/Test Split: Train on past data, Test on newest 1 year\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>105484.76</td>\n",
       "      <td>71462.74</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>110079.05</td>\n",
       "      <td>75278.12</td>\n",
       "      <td>0.9745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>110803.48</td>\n",
       "      <td>74066.48</td>\n",
       "      <td>0.9741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>112924.49</td>\n",
       "      <td>88289.20</td>\n",
       "      <td>0.9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>115904.58</td>\n",
       "      <td>88654.02</td>\n",
       "      <td>0.9717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>116334.73</td>\n",
       "      <td>77569.96</td>\n",
       "      <td>0.9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression</th>\n",
       "      <td>119610.81</td>\n",
       "      <td>94925.42</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>146833.02</td>\n",
       "      <td>98389.01</td>\n",
       "      <td>0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>154547.69</td>\n",
       "      <td>124787.12</td>\n",
       "      <td>0.9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>161897.56</td>\n",
       "      <td>110685.31</td>\n",
       "      <td>0.9448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>169246.64</td>\n",
       "      <td>140651.42</td>\n",
       "      <td>0.9397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>179681.84</td>\n",
       "      <td>143656.77</td>\n",
       "      <td>0.9320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          RMSE        MAE      R²\n",
       "Gradient Boosting    105484.76   71462.74  0.9766\n",
       "Random Forest        110079.05   75278.12  0.9745\n",
       "LightGBM             110803.48   74066.48  0.9741\n",
       "Ridge Regression     112924.49   88289.20  0.9731\n",
       "Linear Regression    115904.58   88654.02  0.9717\n",
       "XGBoost              116334.73   77569.96  0.9715\n",
       "Lasso Regression     119610.81   94925.42  0.9699\n",
       "K-Nearest Neighbors  146833.02   98389.01  0.9546\n",
       "SVR                  154547.69  124787.12  0.9497\n",
       "Decision Tree        161897.56  110685.31  0.9448\n",
       "AdaBoost             169246.64  140651.42  0.9397\n",
       "ElasticNet           179681.84  143656.77  0.9320"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create results DataFrame for optimal dataset\n",
    "results_opt_df = pd.DataFrame(results_opt).T\n",
    "results_opt_df = results_opt_df.sort_values('R2', ascending=False)\n",
    "\n",
    "# Format for display\n",
    "results_opt_display = results_opt_df.copy()\n",
    "results_opt_display['RMSE_fmt'] = results_opt_display['RMSE'].apply(lambda x: f\"{x:.2f}\")\n",
    "results_opt_display['MAE_fmt'] = results_opt_display['MAE'].apply(lambda x: f\"{x:.2f}\")\n",
    "results_opt_display['R²_fmt'] = results_opt_display['R2'].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON RESULTS - OPTIMAL TIMESPAN DATASET (sorted by R² score)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: {len(X_opt)} samples ({optimal_years_overall} years training + 1 year test)\")\n",
    "print(f\"Train/Test Split: Train on past data, Test on newest 1 year\")\n",
    "print()\n",
    "results_opt_display[['RMSE_fmt', 'MAE_fmt', 'R²_fmt']].rename(columns={'RMSE_fmt': 'RMSE', 'MAE_fmt': 'MAE', 'R²_fmt': 'R²'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "a5c0f766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY - OPTIMAL TIMESPAN DATASET\n",
      "================================================================================\n",
      "\n",
      "Best Model: Gradient Boosting\n",
      "   - R² Score: 0.9766\n",
      "   - RMSE: 105484.76\n",
      "   - MAE: 71462.74\n",
      "\n",
      "Target variable (slp) statistics:\n",
      "   - Mean: 913692.63\n",
      "   - Std: 705517.94\n",
      "   - Min: -435171.56\n",
      "   - Max: 2846941.16\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for optimal dataset\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY - OPTIMAL TIMESPAN DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_model_opt = results_opt_df['R2'].idxmax()\n",
    "best_r2_opt = results_opt_df.loc[best_model_opt, 'R2']\n",
    "best_rmse_opt = results_opt_df.loc[best_model_opt, 'RMSE']\n",
    "best_mae_opt = results_opt_df.loc[best_model_opt, 'MAE']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_opt}\")\n",
    "print(f\"   - R² Score: {best_r2_opt:.4f}\")\n",
    "print(f\"   - RMSE: {best_rmse_opt:.2f}\")\n",
    "print(f\"   - MAE: {best_mae_opt:.2f}\")\n",
    "\n",
    "print(f\"\\nTarget variable (slp) statistics:\")\n",
    "print(f\"   - Mean: {y_opt.mean():.2f}\")\n",
    "print(f\"   - Std: {y_opt.std():.2f}\")\n",
    "print(f\"   - Min: {y_opt.min():.2f}\")\n",
    "print(f\"   - Max: {y_opt.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f34132b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "R² SCORE COMPARISON - OPTIMAL TIMESPAN DATASET\n",
      "================================================================================\n",
      "\n",
      "Gradient Boosting         | ██████████████████████████████████████████████████ 0.9766\n",
      "Random Forest             | █████████████████████████████████████████████████ 0.9745\n",
      "LightGBM                  | █████████████████████████████████████████████████ 0.9741\n",
      "Ridge Regression          | █████████████████████████████████████████████████ 0.9731\n",
      "Linear Regression         | █████████████████████████████████████████████████ 0.9717\n",
      "XGBoost                   | █████████████████████████████████████████████████ 0.9715\n",
      "Lasso Regression          | █████████████████████████████████████████████████ 0.9699\n",
      "K-Nearest Neighbors       | ████████████████████████████████████████████████ 0.9546\n",
      "SVR                       | ████████████████████████████████████████████████ 0.9497\n",
      "Decision Tree             | ████████████████████████████████████████████████ 0.9448\n",
      "AdaBoost                  | ████████████████████████████████████████████████ 0.9397\n",
      "ElasticNet                | ███████████████████████████████████████████████ 0.9320\n"
     ]
    }
   ],
   "source": [
    "# Visual comparison for optimal dataset\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"R² SCORE COMPARISON - OPTIMAL TIMESPAN DATASET\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "max_bar_length = 50\n",
    "max_r2_opt = results_opt_df['R2'].max()\n",
    "\n",
    "for model_name in results_opt_df.index:\n",
    "    r2 = results_opt_df.loc[model_name, 'R2']\n",
    "    if r2 > 0:\n",
    "        bar_length = int((r2 / max_r2_opt) * max_bar_length)\n",
    "        bar = '█' * bar_length\n",
    "    else:\n",
    "        bar_length = 0\n",
    "        bar = ''\n",
    "    print(f\"{model_name:25s} | {bar} {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5b87a2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON: FULL DATASET vs OPTIMAL TIMESPAN DATASET\n",
      "================================================================================\n",
      "\n",
      "Full dataset: Train 3196 samples, Test 364 samples\n",
      "Optimal timespan: Train 1096 samples, Test 364 samples\n",
      "\n",
      "              Model  R² (Full Data)  R² (Optimal)  Difference  Change\n",
      "  Gradient Boosting        0.972644      0.976557    0.003913 +0.0039\n",
      "      Random Forest        0.965822      0.974471    0.008649 +0.0086\n",
      "           LightGBM        0.968550      0.974133    0.005583 +0.0056\n",
      "   Ridge Regression        0.954136      0.973134    0.018998 +0.0190\n",
      "  Linear Regression        0.952931      0.971697    0.018766 +0.0188\n",
      "            XGBoost        0.953200      0.971487    0.018286 +0.0183\n",
      "   Lasso Regression        0.951556      0.969858    0.018302 +0.0183\n",
      "K-Nearest Neighbors        0.949234      0.954577    0.005343 +0.0053\n",
      "                SVR        0.946600      0.949678    0.003078 +0.0031\n",
      "      Decision Tree        0.839291      0.944778    0.105487 +0.1055\n",
      "           AdaBoost        0.936491      0.939651    0.003160 +0.0032\n",
      "         ElasticNet        0.917898      0.931979    0.014081 +0.0141\n",
      "\n",
      "12/12 models improved with optimal timespan dataset\n",
      "Average R² change: +0.0186\n"
     ]
    }
   ],
   "source": [
    "# Compare results: Full dataset vs Optimal timespan dataset\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON: FULL DATASET vs OPTIMAL TIMESPAN DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = []\n",
    "for model_name in results_df.index:\n",
    "    if model_name in results_opt_df.index:\n",
    "        r2_full = results_df.loc[model_name, 'R2']\n",
    "        r2_opt = results_opt_df.loc[model_name, 'R2']\n",
    "        diff = r2_opt - r2_full\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'R² (Full Data)': r2_full,\n",
    "            'R² (Optimal)': r2_opt,\n",
    "            'Difference': diff,\n",
    "            'Change': f\"{'+' if diff > 0 else ''}{diff:.4f}\"\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('R² (Optimal)', ascending=False)\n",
    "\n",
    "print(f\"\\nFull dataset: Train {len(X_train_main)} samples, Test {len(X_test_main)} samples\")\n",
    "print(f\"Optimal timespan: Train {len(X_train_opt)} samples, Test {len(X_test_opt)} samples\")\n",
    "print()\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Summary\n",
    "improved = (comparison_df['Difference'] > 0).sum()\n",
    "total = len(comparison_df)\n",
    "print(f\"\\n{improved}/{total} models improved with optimal timespan dataset\")\n",
    "print(f\"Average R² change: {comparison_df['Difference'].mean():+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "539e4697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL CONCLUSION\n",
      "================================================================================\n",
      "\n",
      "Dataset Comparison:\n",
      "  • Full dataset: 3560 samples (~9.7 years)\n",
      "  • Optimal dataset: 1460 samples (4 years)\n",
      "\n",
      "Best Performing Models:\n",
      "  • Full dataset: Gradient Boosting (R² = 0.9726)\n",
      "  • Optimal dataset: Gradient Boosting (R² = 0.9766)\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "RECOMMENDATION:\n",
      "  Using 3 years of training data + 1 year test data achieves\n",
      "  comparable or better results with significantly less data.\n",
      "  \n",
      "  Best model for prediction: Gradient Boosting\n",
      "  Expected R² score: 0.9766\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final conclusion\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL CONCLUSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "Dataset Comparison:\n",
    "  • Full dataset: {len(X_scaled)} samples (~{total_train_years + 1:.1f} years)\n",
    "  • Optimal dataset: {len(X_opt)} samples ({optimal_years_overall + 1} years)\n",
    "\n",
    "Best Performing Models:\n",
    "  • Full dataset: {best_model} (R² = {best_r2:.4f})\n",
    "  • Optimal dataset: {best_model_opt} (R² = {best_r2_opt:.4f})\n",
    "\n",
    "════════════════════════════════════════════════════════════════════════════════\n",
    "RECOMMENDATION:\n",
    "  Using {optimal_years_overall} years of training data + 1 year test data achieves\n",
    "  comparable or better results with significantly less data.\n",
    "  \n",
    "  Best model for prediction: {best_model_opt}\n",
    "  Expected R² score: {best_r2_opt:.4f}\n",
    "════════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
